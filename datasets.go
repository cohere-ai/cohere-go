// Code generated by Fern. DO NOT EDIT.

package api

import (
	json "encoding/json"
	fmt "fmt"
	internal "github.com/cohere-ai/cohere-go/v2/internal"
	io "io"
	big "math/big"
	time "time"
)

var (
	datasetsCreateRequestFieldName               = big.NewInt(1 << 0)
	datasetsCreateRequestFieldType               = big.NewInt(1 << 1)
	datasetsCreateRequestFieldKeepOriginalFile   = big.NewInt(1 << 2)
	datasetsCreateRequestFieldSkipMalformedInput = big.NewInt(1 << 3)
	datasetsCreateRequestFieldKeepFields         = big.NewInt(1 << 4)
	datasetsCreateRequestFieldOptionalFields     = big.NewInt(1 << 5)
	datasetsCreateRequestFieldTextSeparator      = big.NewInt(1 << 6)
	datasetsCreateRequestFieldCsvDelimiter       = big.NewInt(1 << 7)
)

type DatasetsCreateRequest struct {
	// The name of the uploaded dataset.
	Name string `json:"-" url:"name"`
	// The dataset type, which is used to validate the data. The only valid type is `embed-input` used in conjunction with the Embed Jobs API.
	Type DatasetType `json:"-" url:"type"`
	// Indicates if the original file should be stored.
	KeepOriginalFile *bool `json:"-" url:"keep_original_file,omitempty"`
	// Indicates whether rows with malformed input should be dropped (instead of failing the validation check). Dropped rows will be returned in the warnings field.
	SkipMalformedInput *bool `json:"-" url:"skip_malformed_input,omitempty"`
	// List of names of fields that will be persisted in the Dataset. By default the Dataset will retain only the required fields indicated in the [schema for the corresponding Dataset type](https://docs.cohere.com/docs/datasets#dataset-types). For example, datasets of type `embed-input` will drop all fields other than the required `text` field. If any of the fields in `keep_fields` are missing from the uploaded file, Dataset validation will fail.
	KeepFields []*string `json:"-" url:"keep_fields,omitempty"`
	// List of names of fields that will be persisted in the Dataset. By default the Dataset will retain only the required fields indicated in the [schema for the corresponding Dataset type](https://docs.cohere.com/docs/datasets#dataset-types). For example, Datasets of type `embed-input` will drop all fields other than the required `text` field. If any of the fields in `optional_fields` are missing from the uploaded file, Dataset validation will pass.
	OptionalFields []*string `json:"-" url:"optional_fields,omitempty"`
	// Raw .txt uploads will be split into entries using the text_separator value.
	TextSeparator *string `json:"-" url:"text_separator,omitempty"`
	// The delimiter used for .csv uploads.
	CsvDelimiter *string   `json:"-" url:"csv_delimiter,omitempty"`
	Data         io.Reader `json:"-" url:"-"`
	EvalData     io.Reader `json:"-" url:"-"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`
}

func (d *DatasetsCreateRequest) require(field *big.Int) {
	if d.explicitFields == nil {
		d.explicitFields = big.NewInt(0)
	}
	d.explicitFields.Or(d.explicitFields, field)
}

// SetName sets the Name field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsCreateRequest) SetName(name string) {
	d.Name = name
	d.require(datasetsCreateRequestFieldName)
}

// SetType sets the Type field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsCreateRequest) SetType(type_ DatasetType) {
	d.Type = type_
	d.require(datasetsCreateRequestFieldType)
}

// SetKeepOriginalFile sets the KeepOriginalFile field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsCreateRequest) SetKeepOriginalFile(keepOriginalFile *bool) {
	d.KeepOriginalFile = keepOriginalFile
	d.require(datasetsCreateRequestFieldKeepOriginalFile)
}

// SetSkipMalformedInput sets the SkipMalformedInput field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsCreateRequest) SetSkipMalformedInput(skipMalformedInput *bool) {
	d.SkipMalformedInput = skipMalformedInput
	d.require(datasetsCreateRequestFieldSkipMalformedInput)
}

// SetKeepFields sets the KeepFields field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsCreateRequest) SetKeepFields(keepFields []*string) {
	d.KeepFields = keepFields
	d.require(datasetsCreateRequestFieldKeepFields)
}

// SetOptionalFields sets the OptionalFields field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsCreateRequest) SetOptionalFields(optionalFields []*string) {
	d.OptionalFields = optionalFields
	d.require(datasetsCreateRequestFieldOptionalFields)
}

// SetTextSeparator sets the TextSeparator field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsCreateRequest) SetTextSeparator(textSeparator *string) {
	d.TextSeparator = textSeparator
	d.require(datasetsCreateRequestFieldTextSeparator)
}

// SetCsvDelimiter sets the CsvDelimiter field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsCreateRequest) SetCsvDelimiter(csvDelimiter *string) {
	d.CsvDelimiter = csvDelimiter
	d.require(datasetsCreateRequestFieldCsvDelimiter)
}

var (
	datasetsListRequestFieldDatasetType      = big.NewInt(1 << 0)
	datasetsListRequestFieldBefore           = big.NewInt(1 << 1)
	datasetsListRequestFieldAfter            = big.NewInt(1 << 2)
	datasetsListRequestFieldLimit            = big.NewInt(1 << 3)
	datasetsListRequestFieldOffset           = big.NewInt(1 << 4)
	datasetsListRequestFieldValidationStatus = big.NewInt(1 << 5)
)

type DatasetsListRequest struct {
	// optional filter by dataset type
	DatasetType *string `json:"-" url:"datasetType,omitempty"`
	// optional filter before a date
	Before *time.Time `json:"-" url:"before,omitempty"`
	// optional filter after a date
	After *time.Time `json:"-" url:"after,omitempty"`
	// optional limit to number of results
	Limit *float64 `json:"-" url:"limit,omitempty"`
	// optional offset to start of results
	Offset *float64 `json:"-" url:"offset,omitempty"`
	// optional filter by validation status
	ValidationStatus *DatasetValidationStatus `json:"-" url:"validationStatus,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`
}

func (d *DatasetsListRequest) require(field *big.Int) {
	if d.explicitFields == nil {
		d.explicitFields = big.NewInt(0)
	}
	d.explicitFields.Or(d.explicitFields, field)
}

// SetDatasetType sets the DatasetType field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsListRequest) SetDatasetType(datasetType *string) {
	d.DatasetType = datasetType
	d.require(datasetsListRequestFieldDatasetType)
}

// SetBefore sets the Before field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsListRequest) SetBefore(before *time.Time) {
	d.Before = before
	d.require(datasetsListRequestFieldBefore)
}

// SetAfter sets the After field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsListRequest) SetAfter(after *time.Time) {
	d.After = after
	d.require(datasetsListRequestFieldAfter)
}

// SetLimit sets the Limit field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsListRequest) SetLimit(limit *float64) {
	d.Limit = limit
	d.require(datasetsListRequestFieldLimit)
}

// SetOffset sets the Offset field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsListRequest) SetOffset(offset *float64) {
	d.Offset = offset
	d.require(datasetsListRequestFieldOffset)
}

// SetValidationStatus sets the ValidationStatus field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsListRequest) SetValidationStatus(validationStatus *DatasetValidationStatus) {
	d.ValidationStatus = validationStatus
	d.require(datasetsListRequestFieldValidationStatus)
}

var (
	chatDataMetricsFieldNumTrainTurns = big.NewInt(1 << 0)
	chatDataMetricsFieldNumEvalTurns  = big.NewInt(1 << 1)
	chatDataMetricsFieldPreamble      = big.NewInt(1 << 2)
)

type ChatDataMetrics struct {
	// The sum of all turns of valid train examples.
	NumTrainTurns *int64 `json:"num_train_turns,omitempty" url:"num_train_turns,omitempty"`
	// The sum of all turns of valid eval examples.
	NumEvalTurns *int64 `json:"num_eval_turns,omitempty" url:"num_eval_turns,omitempty"`
	// The preamble of this dataset.
	Preamble *string `json:"preamble,omitempty" url:"preamble,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatDataMetrics) GetNumTrainTurns() *int64 {
	if c == nil {
		return nil
	}
	return c.NumTrainTurns
}

func (c *ChatDataMetrics) GetNumEvalTurns() *int64 {
	if c == nil {
		return nil
	}
	return c.NumEvalTurns
}

func (c *ChatDataMetrics) GetPreamble() *string {
	if c == nil {
		return nil
	}
	return c.Preamble
}

func (c *ChatDataMetrics) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatDataMetrics) require(field *big.Int) {
	if c.explicitFields == nil {
		c.explicitFields = big.NewInt(0)
	}
	c.explicitFields.Or(c.explicitFields, field)
}

// SetNumTrainTurns sets the NumTrainTurns field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (c *ChatDataMetrics) SetNumTrainTurns(numTrainTurns *int64) {
	c.NumTrainTurns = numTrainTurns
	c.require(chatDataMetricsFieldNumTrainTurns)
}

// SetNumEvalTurns sets the NumEvalTurns field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (c *ChatDataMetrics) SetNumEvalTurns(numEvalTurns *int64) {
	c.NumEvalTurns = numEvalTurns
	c.require(chatDataMetricsFieldNumEvalTurns)
}

// SetPreamble sets the Preamble field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (c *ChatDataMetrics) SetPreamble(preamble *string) {
	c.Preamble = preamble
	c.require(chatDataMetricsFieldPreamble)
}

func (c *ChatDataMetrics) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatDataMetrics
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatDataMetrics(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatDataMetrics) MarshalJSON() ([]byte, error) {
	type embed ChatDataMetrics
	var marshaler = struct {
		embed
	}{
		embed: embed(*c),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, c.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (c *ChatDataMetrics) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

var (
	classifyDataMetricsFieldLabelMetrics = big.NewInt(1 << 0)
)

type ClassifyDataMetrics struct {
	LabelMetrics []*LabelMetric `json:"label_metrics,omitempty" url:"label_metrics,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ClassifyDataMetrics) GetLabelMetrics() []*LabelMetric {
	if c == nil {
		return nil
	}
	return c.LabelMetrics
}

func (c *ClassifyDataMetrics) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ClassifyDataMetrics) require(field *big.Int) {
	if c.explicitFields == nil {
		c.explicitFields = big.NewInt(0)
	}
	c.explicitFields.Or(c.explicitFields, field)
}

// SetLabelMetrics sets the LabelMetrics field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (c *ClassifyDataMetrics) SetLabelMetrics(labelMetrics []*LabelMetric) {
	c.LabelMetrics = labelMetrics
	c.require(classifyDataMetricsFieldLabelMetrics)
}

func (c *ClassifyDataMetrics) UnmarshalJSON(data []byte) error {
	type unmarshaler ClassifyDataMetrics
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ClassifyDataMetrics(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ClassifyDataMetrics) MarshalJSON() ([]byte, error) {
	type embed ClassifyDataMetrics
	var marshaler = struct {
		embed
	}{
		embed: embed(*c),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, c.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (c *ClassifyDataMetrics) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

var (
	datasetFieldId                 = big.NewInt(1 << 0)
	datasetFieldName               = big.NewInt(1 << 1)
	datasetFieldCreatedAt          = big.NewInt(1 << 2)
	datasetFieldUpdatedAt          = big.NewInt(1 << 3)
	datasetFieldDatasetType        = big.NewInt(1 << 4)
	datasetFieldValidationStatus   = big.NewInt(1 << 5)
	datasetFieldValidationError    = big.NewInt(1 << 6)
	datasetFieldSchema             = big.NewInt(1 << 7)
	datasetFieldRequiredFields     = big.NewInt(1 << 8)
	datasetFieldPreserveFields     = big.NewInt(1 << 9)
	datasetFieldDatasetParts       = big.NewInt(1 << 10)
	datasetFieldValidationWarnings = big.NewInt(1 << 11)
)

type Dataset struct {
	// The dataset ID
	Id string `json:"id" url:"id"`
	// The name of the dataset
	Name string `json:"name" url:"name"`
	// The creation date
	CreatedAt time.Time `json:"created_at" url:"created_at"`
	// The last update date
	UpdatedAt        time.Time               `json:"updated_at" url:"updated_at"`
	DatasetType      DatasetType             `json:"dataset_type" url:"dataset_type"`
	ValidationStatus DatasetValidationStatus `json:"validation_status" url:"validation_status"`
	// Errors found during validation
	ValidationError *string `json:"validation_error,omitempty" url:"validation_error,omitempty"`
	// the avro schema of the dataset
	Schema         *string  `json:"schema,omitempty" url:"schema,omitempty"`
	RequiredFields []string `json:"required_fields,omitempty" url:"required_fields,omitempty"`
	PreserveFields []string `json:"preserve_fields,omitempty" url:"preserve_fields,omitempty"`
	// the underlying files that make up the dataset
	DatasetParts []*DatasetPart `json:"dataset_parts,omitempty" url:"dataset_parts,omitempty"`
	// warnings found during validation
	ValidationWarnings []string `json:"validation_warnings,omitempty" url:"validation_warnings,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (d *Dataset) GetId() string {
	if d == nil {
		return ""
	}
	return d.Id
}

func (d *Dataset) GetName() string {
	if d == nil {
		return ""
	}
	return d.Name
}

func (d *Dataset) GetCreatedAt() time.Time {
	if d == nil {
		return time.Time{}
	}
	return d.CreatedAt
}

func (d *Dataset) GetUpdatedAt() time.Time {
	if d == nil {
		return time.Time{}
	}
	return d.UpdatedAt
}

func (d *Dataset) GetDatasetType() DatasetType {
	if d == nil {
		return ""
	}
	return d.DatasetType
}

func (d *Dataset) GetValidationStatus() DatasetValidationStatus {
	if d == nil {
		return ""
	}
	return d.ValidationStatus
}

func (d *Dataset) GetValidationError() *string {
	if d == nil {
		return nil
	}
	return d.ValidationError
}

func (d *Dataset) GetSchema() *string {
	if d == nil {
		return nil
	}
	return d.Schema
}

func (d *Dataset) GetRequiredFields() []string {
	if d == nil {
		return nil
	}
	return d.RequiredFields
}

func (d *Dataset) GetPreserveFields() []string {
	if d == nil {
		return nil
	}
	return d.PreserveFields
}

func (d *Dataset) GetDatasetParts() []*DatasetPart {
	if d == nil {
		return nil
	}
	return d.DatasetParts
}

func (d *Dataset) GetValidationWarnings() []string {
	if d == nil {
		return nil
	}
	return d.ValidationWarnings
}

func (d *Dataset) GetExtraProperties() map[string]interface{} {
	return d.extraProperties
}

func (d *Dataset) require(field *big.Int) {
	if d.explicitFields == nil {
		d.explicitFields = big.NewInt(0)
	}
	d.explicitFields.Or(d.explicitFields, field)
}

// SetId sets the Id field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetId(id string) {
	d.Id = id
	d.require(datasetFieldId)
}

// SetName sets the Name field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetName(name string) {
	d.Name = name
	d.require(datasetFieldName)
}

// SetCreatedAt sets the CreatedAt field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetCreatedAt(createdAt time.Time) {
	d.CreatedAt = createdAt
	d.require(datasetFieldCreatedAt)
}

// SetUpdatedAt sets the UpdatedAt field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetUpdatedAt(updatedAt time.Time) {
	d.UpdatedAt = updatedAt
	d.require(datasetFieldUpdatedAt)
}

// SetDatasetType sets the DatasetType field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetDatasetType(datasetType DatasetType) {
	d.DatasetType = datasetType
	d.require(datasetFieldDatasetType)
}

// SetValidationStatus sets the ValidationStatus field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetValidationStatus(validationStatus DatasetValidationStatus) {
	d.ValidationStatus = validationStatus
	d.require(datasetFieldValidationStatus)
}

// SetValidationError sets the ValidationError field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetValidationError(validationError *string) {
	d.ValidationError = validationError
	d.require(datasetFieldValidationError)
}

// SetSchema sets the Schema field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetSchema(schema *string) {
	d.Schema = schema
	d.require(datasetFieldSchema)
}

// SetRequiredFields sets the RequiredFields field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetRequiredFields(requiredFields []string) {
	d.RequiredFields = requiredFields
	d.require(datasetFieldRequiredFields)
}

// SetPreserveFields sets the PreserveFields field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetPreserveFields(preserveFields []string) {
	d.PreserveFields = preserveFields
	d.require(datasetFieldPreserveFields)
}

// SetDatasetParts sets the DatasetParts field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetDatasetParts(datasetParts []*DatasetPart) {
	d.DatasetParts = datasetParts
	d.require(datasetFieldDatasetParts)
}

// SetValidationWarnings sets the ValidationWarnings field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *Dataset) SetValidationWarnings(validationWarnings []string) {
	d.ValidationWarnings = validationWarnings
	d.require(datasetFieldValidationWarnings)
}

func (d *Dataset) UnmarshalJSON(data []byte) error {
	type embed Dataset
	var unmarshaler = struct {
		embed
		CreatedAt *internal.DateTime `json:"created_at"`
		UpdatedAt *internal.DateTime `json:"updated_at"`
	}{
		embed: embed(*d),
	}
	if err := json.Unmarshal(data, &unmarshaler); err != nil {
		return err
	}
	*d = Dataset(unmarshaler.embed)
	d.CreatedAt = unmarshaler.CreatedAt.Time()
	d.UpdatedAt = unmarshaler.UpdatedAt.Time()
	extraProperties, err := internal.ExtractExtraProperties(data, *d)
	if err != nil {
		return err
	}
	d.extraProperties = extraProperties
	d.rawJSON = json.RawMessage(data)
	return nil
}

func (d *Dataset) MarshalJSON() ([]byte, error) {
	type embed Dataset
	var marshaler = struct {
		embed
		CreatedAt *internal.DateTime `json:"created_at"`
		UpdatedAt *internal.DateTime `json:"updated_at"`
	}{
		embed:     embed(*d),
		CreatedAt: internal.NewDateTime(d.CreatedAt),
		UpdatedAt: internal.NewDateTime(d.UpdatedAt),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, d.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (d *Dataset) String() string {
	if len(d.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(d.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(d); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", d)
}

var (
	datasetPartFieldId          = big.NewInt(1 << 0)
	datasetPartFieldName        = big.NewInt(1 << 1)
	datasetPartFieldUrl         = big.NewInt(1 << 2)
	datasetPartFieldIndex       = big.NewInt(1 << 3)
	datasetPartFieldSizeBytes   = big.NewInt(1 << 4)
	datasetPartFieldNumRows     = big.NewInt(1 << 5)
	datasetPartFieldOriginalUrl = big.NewInt(1 << 6)
	datasetPartFieldSamples     = big.NewInt(1 << 7)
)

type DatasetPart struct {
	// The dataset part ID
	Id string `json:"id" url:"id"`
	// The name of the dataset part
	Name string `json:"name" url:"name"`
	// The download url of the file
	Url *string `json:"url,omitempty" url:"url,omitempty"`
	// The index of the file
	Index *int `json:"index,omitempty" url:"index,omitempty"`
	// The size of the file in bytes
	SizeBytes *int `json:"size_bytes,omitempty" url:"size_bytes,omitempty"`
	// The number of rows in the file
	NumRows *int `json:"num_rows,omitempty" url:"num_rows,omitempty"`
	// The download url of the original file
	OriginalUrl *string `json:"original_url,omitempty" url:"original_url,omitempty"`
	// The first few rows of the parsed file
	Samples []string `json:"samples,omitempty" url:"samples,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (d *DatasetPart) GetId() string {
	if d == nil {
		return ""
	}
	return d.Id
}

func (d *DatasetPart) GetName() string {
	if d == nil {
		return ""
	}
	return d.Name
}

func (d *DatasetPart) GetUrl() *string {
	if d == nil {
		return nil
	}
	return d.Url
}

func (d *DatasetPart) GetIndex() *int {
	if d == nil {
		return nil
	}
	return d.Index
}

func (d *DatasetPart) GetSizeBytes() *int {
	if d == nil {
		return nil
	}
	return d.SizeBytes
}

func (d *DatasetPart) GetNumRows() *int {
	if d == nil {
		return nil
	}
	return d.NumRows
}

func (d *DatasetPart) GetOriginalUrl() *string {
	if d == nil {
		return nil
	}
	return d.OriginalUrl
}

func (d *DatasetPart) GetSamples() []string {
	if d == nil {
		return nil
	}
	return d.Samples
}

func (d *DatasetPart) GetExtraProperties() map[string]interface{} {
	return d.extraProperties
}

func (d *DatasetPart) require(field *big.Int) {
	if d.explicitFields == nil {
		d.explicitFields = big.NewInt(0)
	}
	d.explicitFields.Or(d.explicitFields, field)
}

// SetId sets the Id field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetPart) SetId(id string) {
	d.Id = id
	d.require(datasetPartFieldId)
}

// SetName sets the Name field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetPart) SetName(name string) {
	d.Name = name
	d.require(datasetPartFieldName)
}

// SetUrl sets the Url field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetPart) SetUrl(url *string) {
	d.Url = url
	d.require(datasetPartFieldUrl)
}

// SetIndex sets the Index field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetPart) SetIndex(index *int) {
	d.Index = index
	d.require(datasetPartFieldIndex)
}

// SetSizeBytes sets the SizeBytes field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetPart) SetSizeBytes(sizeBytes *int) {
	d.SizeBytes = sizeBytes
	d.require(datasetPartFieldSizeBytes)
}

// SetNumRows sets the NumRows field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetPart) SetNumRows(numRows *int) {
	d.NumRows = numRows
	d.require(datasetPartFieldNumRows)
}

// SetOriginalUrl sets the OriginalUrl field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetPart) SetOriginalUrl(originalUrl *string) {
	d.OriginalUrl = originalUrl
	d.require(datasetPartFieldOriginalUrl)
}

// SetSamples sets the Samples field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetPart) SetSamples(samples []string) {
	d.Samples = samples
	d.require(datasetPartFieldSamples)
}

func (d *DatasetPart) UnmarshalJSON(data []byte) error {
	type unmarshaler DatasetPart
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*d = DatasetPart(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *d)
	if err != nil {
		return err
	}
	d.extraProperties = extraProperties
	d.rawJSON = json.RawMessage(data)
	return nil
}

func (d *DatasetPart) MarshalJSON() ([]byte, error) {
	type embed DatasetPart
	var marshaler = struct {
		embed
	}{
		embed: embed(*d),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, d.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (d *DatasetPart) String() string {
	if len(d.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(d.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(d); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", d)
}

// The type of the dataset
type DatasetType string

const (
	DatasetTypeEmbedInput                             DatasetType = "embed-input"
	DatasetTypeEmbedResult                            DatasetType = "embed-result"
	DatasetTypeClusterResult                          DatasetType = "cluster-result"
	DatasetTypeClusterOutliers                        DatasetType = "cluster-outliers"
	DatasetTypeRerankerFinetuneInput                  DatasetType = "reranker-finetune-input"
	DatasetTypeSingleLabelClassificationFinetuneInput DatasetType = "single-label-classification-finetune-input"
	DatasetTypeChatFinetuneInput                      DatasetType = "chat-finetune-input"
	DatasetTypeMultiLabelClassificationFinetuneInput  DatasetType = "multi-label-classification-finetune-input"
	DatasetTypeBatchChatInput                         DatasetType = "batch-chat-input"
	DatasetTypeBatchOpenaiChatInput                   DatasetType = "batch-openai-chat-input"
	DatasetTypeBatchEmbedV2Input                      DatasetType = "batch-embed-v2-input"
	DatasetTypeBatchChatV2Input                       DatasetType = "batch-chat-v2-input"
)

func NewDatasetTypeFromString(s string) (DatasetType, error) {
	switch s {
	case "embed-input":
		return DatasetTypeEmbedInput, nil
	case "embed-result":
		return DatasetTypeEmbedResult, nil
	case "cluster-result":
		return DatasetTypeClusterResult, nil
	case "cluster-outliers":
		return DatasetTypeClusterOutliers, nil
	case "reranker-finetune-input":
		return DatasetTypeRerankerFinetuneInput, nil
	case "single-label-classification-finetune-input":
		return DatasetTypeSingleLabelClassificationFinetuneInput, nil
	case "chat-finetune-input":
		return DatasetTypeChatFinetuneInput, nil
	case "multi-label-classification-finetune-input":
		return DatasetTypeMultiLabelClassificationFinetuneInput, nil
	case "batch-chat-input":
		return DatasetTypeBatchChatInput, nil
	case "batch-openai-chat-input":
		return DatasetTypeBatchOpenaiChatInput, nil
	case "batch-embed-v2-input":
		return DatasetTypeBatchEmbedV2Input, nil
	case "batch-chat-v2-input":
		return DatasetTypeBatchChatV2Input, nil
	}
	var t DatasetType
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (d DatasetType) Ptr() *DatasetType {
	return &d
}

// The validation status of the dataset
type DatasetValidationStatus string

const (
	DatasetValidationStatusUnknown    DatasetValidationStatus = "unknown"
	DatasetValidationStatusQueued     DatasetValidationStatus = "queued"
	DatasetValidationStatusProcessing DatasetValidationStatus = "processing"
	DatasetValidationStatusFailed     DatasetValidationStatus = "failed"
	DatasetValidationStatusValidated  DatasetValidationStatus = "validated"
	DatasetValidationStatusSkipped    DatasetValidationStatus = "skipped"
)

func NewDatasetValidationStatusFromString(s string) (DatasetValidationStatus, error) {
	switch s {
	case "unknown":
		return DatasetValidationStatusUnknown, nil
	case "queued":
		return DatasetValidationStatusQueued, nil
	case "processing":
		return DatasetValidationStatusProcessing, nil
	case "failed":
		return DatasetValidationStatusFailed, nil
	case "validated":
		return DatasetValidationStatusValidated, nil
	case "skipped":
		return DatasetValidationStatusSkipped, nil
	}
	var t DatasetValidationStatus
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (d DatasetValidationStatus) Ptr() *DatasetValidationStatus {
	return &d
}

var (
	finetuneDatasetMetricsFieldTrainableTokenCount = big.NewInt(1 << 0)
	finetuneDatasetMetricsFieldTotalExamples       = big.NewInt(1 << 1)
	finetuneDatasetMetricsFieldTrainExamples       = big.NewInt(1 << 2)
	finetuneDatasetMetricsFieldTrainSizeBytes      = big.NewInt(1 << 3)
	finetuneDatasetMetricsFieldEvalExamples        = big.NewInt(1 << 4)
	finetuneDatasetMetricsFieldEvalSizeBytes       = big.NewInt(1 << 5)
)

type FinetuneDatasetMetrics struct {
	// The number of tokens of valid examples that can be used for training.
	TrainableTokenCount *int64 `json:"trainable_token_count,omitempty" url:"trainable_token_count,omitempty"`
	// The overall number of examples.
	TotalExamples *int64 `json:"total_examples,omitempty" url:"total_examples,omitempty"`
	// The number of training examples.
	TrainExamples *int64 `json:"train_examples,omitempty" url:"train_examples,omitempty"`
	// The size in bytes of all training examples.
	TrainSizeBytes *int64 `json:"train_size_bytes,omitempty" url:"train_size_bytes,omitempty"`
	// Number of evaluation examples.
	EvalExamples *int64 `json:"eval_examples,omitempty" url:"eval_examples,omitempty"`
	// The size in bytes of all eval examples.
	EvalSizeBytes *int64 `json:"eval_size_bytes,omitempty" url:"eval_size_bytes,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (f *FinetuneDatasetMetrics) GetTrainableTokenCount() *int64 {
	if f == nil {
		return nil
	}
	return f.TrainableTokenCount
}

func (f *FinetuneDatasetMetrics) GetTotalExamples() *int64 {
	if f == nil {
		return nil
	}
	return f.TotalExamples
}

func (f *FinetuneDatasetMetrics) GetTrainExamples() *int64 {
	if f == nil {
		return nil
	}
	return f.TrainExamples
}

func (f *FinetuneDatasetMetrics) GetTrainSizeBytes() *int64 {
	if f == nil {
		return nil
	}
	return f.TrainSizeBytes
}

func (f *FinetuneDatasetMetrics) GetEvalExamples() *int64 {
	if f == nil {
		return nil
	}
	return f.EvalExamples
}

func (f *FinetuneDatasetMetrics) GetEvalSizeBytes() *int64 {
	if f == nil {
		return nil
	}
	return f.EvalSizeBytes
}

func (f *FinetuneDatasetMetrics) GetExtraProperties() map[string]interface{} {
	return f.extraProperties
}

func (f *FinetuneDatasetMetrics) require(field *big.Int) {
	if f.explicitFields == nil {
		f.explicitFields = big.NewInt(0)
	}
	f.explicitFields.Or(f.explicitFields, field)
}

// SetTrainableTokenCount sets the TrainableTokenCount field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (f *FinetuneDatasetMetrics) SetTrainableTokenCount(trainableTokenCount *int64) {
	f.TrainableTokenCount = trainableTokenCount
	f.require(finetuneDatasetMetricsFieldTrainableTokenCount)
}

// SetTotalExamples sets the TotalExamples field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (f *FinetuneDatasetMetrics) SetTotalExamples(totalExamples *int64) {
	f.TotalExamples = totalExamples
	f.require(finetuneDatasetMetricsFieldTotalExamples)
}

// SetTrainExamples sets the TrainExamples field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (f *FinetuneDatasetMetrics) SetTrainExamples(trainExamples *int64) {
	f.TrainExamples = trainExamples
	f.require(finetuneDatasetMetricsFieldTrainExamples)
}

// SetTrainSizeBytes sets the TrainSizeBytes field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (f *FinetuneDatasetMetrics) SetTrainSizeBytes(trainSizeBytes *int64) {
	f.TrainSizeBytes = trainSizeBytes
	f.require(finetuneDatasetMetricsFieldTrainSizeBytes)
}

// SetEvalExamples sets the EvalExamples field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (f *FinetuneDatasetMetrics) SetEvalExamples(evalExamples *int64) {
	f.EvalExamples = evalExamples
	f.require(finetuneDatasetMetricsFieldEvalExamples)
}

// SetEvalSizeBytes sets the EvalSizeBytes field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (f *FinetuneDatasetMetrics) SetEvalSizeBytes(evalSizeBytes *int64) {
	f.EvalSizeBytes = evalSizeBytes
	f.require(finetuneDatasetMetricsFieldEvalSizeBytes)
}

func (f *FinetuneDatasetMetrics) UnmarshalJSON(data []byte) error {
	type unmarshaler FinetuneDatasetMetrics
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*f = FinetuneDatasetMetrics(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *f)
	if err != nil {
		return err
	}
	f.extraProperties = extraProperties
	f.rawJSON = json.RawMessage(data)
	return nil
}

func (f *FinetuneDatasetMetrics) MarshalJSON() ([]byte, error) {
	type embed FinetuneDatasetMetrics
	var marshaler = struct {
		embed
	}{
		embed: embed(*f),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, f.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (f *FinetuneDatasetMetrics) String() string {
	if len(f.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(f.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(f); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", f)
}

var (
	labelMetricFieldTotalExamples = big.NewInt(1 << 0)
	labelMetricFieldLabel         = big.NewInt(1 << 1)
	labelMetricFieldSamples       = big.NewInt(1 << 2)
)

type LabelMetric struct {
	// Total number of examples for this label
	TotalExamples *int64 `json:"total_examples,omitempty" url:"total_examples,omitempty"`
	// value of the label
	Label *string `json:"label,omitempty" url:"label,omitempty"`
	// samples for this label
	Samples []string `json:"samples,omitempty" url:"samples,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (l *LabelMetric) GetTotalExamples() *int64 {
	if l == nil {
		return nil
	}
	return l.TotalExamples
}

func (l *LabelMetric) GetLabel() *string {
	if l == nil {
		return nil
	}
	return l.Label
}

func (l *LabelMetric) GetSamples() []string {
	if l == nil {
		return nil
	}
	return l.Samples
}

func (l *LabelMetric) GetExtraProperties() map[string]interface{} {
	return l.extraProperties
}

func (l *LabelMetric) require(field *big.Int) {
	if l.explicitFields == nil {
		l.explicitFields = big.NewInt(0)
	}
	l.explicitFields.Or(l.explicitFields, field)
}

// SetTotalExamples sets the TotalExamples field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (l *LabelMetric) SetTotalExamples(totalExamples *int64) {
	l.TotalExamples = totalExamples
	l.require(labelMetricFieldTotalExamples)
}

// SetLabel sets the Label field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (l *LabelMetric) SetLabel(label *string) {
	l.Label = label
	l.require(labelMetricFieldLabel)
}

// SetSamples sets the Samples field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (l *LabelMetric) SetSamples(samples []string) {
	l.Samples = samples
	l.require(labelMetricFieldSamples)
}

func (l *LabelMetric) UnmarshalJSON(data []byte) error {
	type unmarshaler LabelMetric
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*l = LabelMetric(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *l)
	if err != nil {
		return err
	}
	l.extraProperties = extraProperties
	l.rawJSON = json.RawMessage(data)
	return nil
}

func (l *LabelMetric) MarshalJSON() ([]byte, error) {
	type embed LabelMetric
	var marshaler = struct {
		embed
	}{
		embed: embed(*l),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, l.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (l *LabelMetric) String() string {
	if len(l.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(l.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(l); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", l)
}

var (
	metricsFieldFinetuneDatasetMetrics = big.NewInt(1 << 0)
)

type Metrics struct {
	FinetuneDatasetMetrics *FinetuneDatasetMetrics `json:"finetune_dataset_metrics,omitempty" url:"finetune_dataset_metrics,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (m *Metrics) GetFinetuneDatasetMetrics() *FinetuneDatasetMetrics {
	if m == nil {
		return nil
	}
	return m.FinetuneDatasetMetrics
}

func (m *Metrics) GetExtraProperties() map[string]interface{} {
	return m.extraProperties
}

func (m *Metrics) require(field *big.Int) {
	if m.explicitFields == nil {
		m.explicitFields = big.NewInt(0)
	}
	m.explicitFields.Or(m.explicitFields, field)
}

// SetFinetuneDatasetMetrics sets the FinetuneDatasetMetrics field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (m *Metrics) SetFinetuneDatasetMetrics(finetuneDatasetMetrics *FinetuneDatasetMetrics) {
	m.FinetuneDatasetMetrics = finetuneDatasetMetrics
	m.require(metricsFieldFinetuneDatasetMetrics)
}

func (m *Metrics) UnmarshalJSON(data []byte) error {
	type unmarshaler Metrics
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*m = Metrics(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *m)
	if err != nil {
		return err
	}
	m.extraProperties = extraProperties
	m.rawJSON = json.RawMessage(data)
	return nil
}

func (m *Metrics) MarshalJSON() ([]byte, error) {
	type embed Metrics
	var marshaler = struct {
		embed
	}{
		embed: embed(*m),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, m.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (m *Metrics) String() string {
	if len(m.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(m.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(m); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", m)
}

var (
	parseInfoFieldSeparator = big.NewInt(1 << 0)
	parseInfoFieldDelimiter = big.NewInt(1 << 1)
)

type ParseInfo struct {
	Separator *string `json:"separator,omitempty" url:"separator,omitempty"`
	Delimiter *string `json:"delimiter,omitempty" url:"delimiter,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (p *ParseInfo) GetSeparator() *string {
	if p == nil {
		return nil
	}
	return p.Separator
}

func (p *ParseInfo) GetDelimiter() *string {
	if p == nil {
		return nil
	}
	return p.Delimiter
}

func (p *ParseInfo) GetExtraProperties() map[string]interface{} {
	return p.extraProperties
}

func (p *ParseInfo) require(field *big.Int) {
	if p.explicitFields == nil {
		p.explicitFields = big.NewInt(0)
	}
	p.explicitFields.Or(p.explicitFields, field)
}

// SetSeparator sets the Separator field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (p *ParseInfo) SetSeparator(separator *string) {
	p.Separator = separator
	p.require(parseInfoFieldSeparator)
}

// SetDelimiter sets the Delimiter field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (p *ParseInfo) SetDelimiter(delimiter *string) {
	p.Delimiter = delimiter
	p.require(parseInfoFieldDelimiter)
}

func (p *ParseInfo) UnmarshalJSON(data []byte) error {
	type unmarshaler ParseInfo
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*p = ParseInfo(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *p)
	if err != nil {
		return err
	}
	p.extraProperties = extraProperties
	p.rawJSON = json.RawMessage(data)
	return nil
}

func (p *ParseInfo) MarshalJSON() ([]byte, error) {
	type embed ParseInfo
	var marshaler = struct {
		embed
	}{
		embed: embed(*p),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, p.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (p *ParseInfo) String() string {
	if len(p.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(p.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(p); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", p)
}

var (
	rerankerDataMetricsFieldNumTrainQueries          = big.NewInt(1 << 0)
	rerankerDataMetricsFieldNumTrainRelevantPassages = big.NewInt(1 << 1)
	rerankerDataMetricsFieldNumTrainHardNegatives    = big.NewInt(1 << 2)
	rerankerDataMetricsFieldNumEvalQueries           = big.NewInt(1 << 3)
	rerankerDataMetricsFieldNumEvalRelevantPassages  = big.NewInt(1 << 4)
	rerankerDataMetricsFieldNumEvalHardNegatives     = big.NewInt(1 << 5)
)

type RerankerDataMetrics struct {
	// The number of training queries.
	NumTrainQueries *int64 `json:"num_train_queries,omitempty" url:"num_train_queries,omitempty"`
	// The sum of all relevant passages of valid training examples.
	NumTrainRelevantPassages *int64 `json:"num_train_relevant_passages,omitempty" url:"num_train_relevant_passages,omitempty"`
	// The sum of all hard negatives of valid training examples.
	NumTrainHardNegatives *int64 `json:"num_train_hard_negatives,omitempty" url:"num_train_hard_negatives,omitempty"`
	// The number of evaluation queries.
	NumEvalQueries *int64 `json:"num_eval_queries,omitempty" url:"num_eval_queries,omitempty"`
	// The sum of all relevant passages of valid eval examples.
	NumEvalRelevantPassages *int64 `json:"num_eval_relevant_passages,omitempty" url:"num_eval_relevant_passages,omitempty"`
	// The sum of all hard negatives of valid eval examples.
	NumEvalHardNegatives *int64 `json:"num_eval_hard_negatives,omitempty" url:"num_eval_hard_negatives,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (r *RerankerDataMetrics) GetNumTrainQueries() *int64 {
	if r == nil {
		return nil
	}
	return r.NumTrainQueries
}

func (r *RerankerDataMetrics) GetNumTrainRelevantPassages() *int64 {
	if r == nil {
		return nil
	}
	return r.NumTrainRelevantPassages
}

func (r *RerankerDataMetrics) GetNumTrainHardNegatives() *int64 {
	if r == nil {
		return nil
	}
	return r.NumTrainHardNegatives
}

func (r *RerankerDataMetrics) GetNumEvalQueries() *int64 {
	if r == nil {
		return nil
	}
	return r.NumEvalQueries
}

func (r *RerankerDataMetrics) GetNumEvalRelevantPassages() *int64 {
	if r == nil {
		return nil
	}
	return r.NumEvalRelevantPassages
}

func (r *RerankerDataMetrics) GetNumEvalHardNegatives() *int64 {
	if r == nil {
		return nil
	}
	return r.NumEvalHardNegatives
}

func (r *RerankerDataMetrics) GetExtraProperties() map[string]interface{} {
	return r.extraProperties
}

func (r *RerankerDataMetrics) require(field *big.Int) {
	if r.explicitFields == nil {
		r.explicitFields = big.NewInt(0)
	}
	r.explicitFields.Or(r.explicitFields, field)
}

// SetNumTrainQueries sets the NumTrainQueries field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (r *RerankerDataMetrics) SetNumTrainQueries(numTrainQueries *int64) {
	r.NumTrainQueries = numTrainQueries
	r.require(rerankerDataMetricsFieldNumTrainQueries)
}

// SetNumTrainRelevantPassages sets the NumTrainRelevantPassages field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (r *RerankerDataMetrics) SetNumTrainRelevantPassages(numTrainRelevantPassages *int64) {
	r.NumTrainRelevantPassages = numTrainRelevantPassages
	r.require(rerankerDataMetricsFieldNumTrainRelevantPassages)
}

// SetNumTrainHardNegatives sets the NumTrainHardNegatives field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (r *RerankerDataMetrics) SetNumTrainHardNegatives(numTrainHardNegatives *int64) {
	r.NumTrainHardNegatives = numTrainHardNegatives
	r.require(rerankerDataMetricsFieldNumTrainHardNegatives)
}

// SetNumEvalQueries sets the NumEvalQueries field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (r *RerankerDataMetrics) SetNumEvalQueries(numEvalQueries *int64) {
	r.NumEvalQueries = numEvalQueries
	r.require(rerankerDataMetricsFieldNumEvalQueries)
}

// SetNumEvalRelevantPassages sets the NumEvalRelevantPassages field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (r *RerankerDataMetrics) SetNumEvalRelevantPassages(numEvalRelevantPassages *int64) {
	r.NumEvalRelevantPassages = numEvalRelevantPassages
	r.require(rerankerDataMetricsFieldNumEvalRelevantPassages)
}

// SetNumEvalHardNegatives sets the NumEvalHardNegatives field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (r *RerankerDataMetrics) SetNumEvalHardNegatives(numEvalHardNegatives *int64) {
	r.NumEvalHardNegatives = numEvalHardNegatives
	r.require(rerankerDataMetricsFieldNumEvalHardNegatives)
}

func (r *RerankerDataMetrics) UnmarshalJSON(data []byte) error {
	type unmarshaler RerankerDataMetrics
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*r = RerankerDataMetrics(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *r)
	if err != nil {
		return err
	}
	r.extraProperties = extraProperties
	r.rawJSON = json.RawMessage(data)
	return nil
}

func (r *RerankerDataMetrics) MarshalJSON() ([]byte, error) {
	type embed RerankerDataMetrics
	var marshaler = struct {
		embed
	}{
		embed: embed(*r),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, r.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (r *RerankerDataMetrics) String() string {
	if len(r.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(r.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(r); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", r)
}

var (
	datasetsCreateResponseFieldId = big.NewInt(1 << 0)
)

type DatasetsCreateResponse struct {
	// The dataset ID
	Id *string `json:"id,omitempty" url:"id,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (d *DatasetsCreateResponse) GetId() *string {
	if d == nil {
		return nil
	}
	return d.Id
}

func (d *DatasetsCreateResponse) GetExtraProperties() map[string]interface{} {
	return d.extraProperties
}

func (d *DatasetsCreateResponse) require(field *big.Int) {
	if d.explicitFields == nil {
		d.explicitFields = big.NewInt(0)
	}
	d.explicitFields.Or(d.explicitFields, field)
}

// SetId sets the Id field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsCreateResponse) SetId(id *string) {
	d.Id = id
	d.require(datasetsCreateResponseFieldId)
}

func (d *DatasetsCreateResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler DatasetsCreateResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*d = DatasetsCreateResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *d)
	if err != nil {
		return err
	}
	d.extraProperties = extraProperties
	d.rawJSON = json.RawMessage(data)
	return nil
}

func (d *DatasetsCreateResponse) MarshalJSON() ([]byte, error) {
	type embed DatasetsCreateResponse
	var marshaler = struct {
		embed
	}{
		embed: embed(*d),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, d.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (d *DatasetsCreateResponse) String() string {
	if len(d.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(d.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(d); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", d)
}

var (
	datasetsGetResponseFieldDataset = big.NewInt(1 << 0)
)

type DatasetsGetResponse struct {
	Dataset *Dataset `json:"dataset" url:"dataset"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (d *DatasetsGetResponse) GetDataset() *Dataset {
	if d == nil {
		return nil
	}
	return d.Dataset
}

func (d *DatasetsGetResponse) GetExtraProperties() map[string]interface{} {
	return d.extraProperties
}

func (d *DatasetsGetResponse) require(field *big.Int) {
	if d.explicitFields == nil {
		d.explicitFields = big.NewInt(0)
	}
	d.explicitFields.Or(d.explicitFields, field)
}

// SetDataset sets the Dataset field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsGetResponse) SetDataset(dataset *Dataset) {
	d.Dataset = dataset
	d.require(datasetsGetResponseFieldDataset)
}

func (d *DatasetsGetResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler DatasetsGetResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*d = DatasetsGetResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *d)
	if err != nil {
		return err
	}
	d.extraProperties = extraProperties
	d.rawJSON = json.RawMessage(data)
	return nil
}

func (d *DatasetsGetResponse) MarshalJSON() ([]byte, error) {
	type embed DatasetsGetResponse
	var marshaler = struct {
		embed
	}{
		embed: embed(*d),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, d.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (d *DatasetsGetResponse) String() string {
	if len(d.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(d.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(d); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", d)
}

var (
	datasetsGetUsageResponseFieldOrganizationUsage = big.NewInt(1 << 0)
)

type DatasetsGetUsageResponse struct {
	// The total number of bytes used by the organization.
	OrganizationUsage *int64 `json:"organization_usage,omitempty" url:"organization_usage,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (d *DatasetsGetUsageResponse) GetOrganizationUsage() *int64 {
	if d == nil {
		return nil
	}
	return d.OrganizationUsage
}

func (d *DatasetsGetUsageResponse) GetExtraProperties() map[string]interface{} {
	return d.extraProperties
}

func (d *DatasetsGetUsageResponse) require(field *big.Int) {
	if d.explicitFields == nil {
		d.explicitFields = big.NewInt(0)
	}
	d.explicitFields.Or(d.explicitFields, field)
}

// SetOrganizationUsage sets the OrganizationUsage field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsGetUsageResponse) SetOrganizationUsage(organizationUsage *int64) {
	d.OrganizationUsage = organizationUsage
	d.require(datasetsGetUsageResponseFieldOrganizationUsage)
}

func (d *DatasetsGetUsageResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler DatasetsGetUsageResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*d = DatasetsGetUsageResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *d)
	if err != nil {
		return err
	}
	d.extraProperties = extraProperties
	d.rawJSON = json.RawMessage(data)
	return nil
}

func (d *DatasetsGetUsageResponse) MarshalJSON() ([]byte, error) {
	type embed DatasetsGetUsageResponse
	var marshaler = struct {
		embed
	}{
		embed: embed(*d),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, d.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (d *DatasetsGetUsageResponse) String() string {
	if len(d.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(d.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(d); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", d)
}

var (
	datasetsListResponseFieldDatasets = big.NewInt(1 << 0)
)

type DatasetsListResponse struct {
	Datasets []*Dataset `json:"datasets,omitempty" url:"datasets,omitempty"`

	// Private bitmask of fields set to an explicit value and therefore not to be omitted
	explicitFields *big.Int `json:"-" url:"-"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (d *DatasetsListResponse) GetDatasets() []*Dataset {
	if d == nil {
		return nil
	}
	return d.Datasets
}

func (d *DatasetsListResponse) GetExtraProperties() map[string]interface{} {
	return d.extraProperties
}

func (d *DatasetsListResponse) require(field *big.Int) {
	if d.explicitFields == nil {
		d.explicitFields = big.NewInt(0)
	}
	d.explicitFields.Or(d.explicitFields, field)
}

// SetDatasets sets the Datasets field and marks it as non-optional;
// this prevents an empty or null value for this field from being omitted during serialization.
func (d *DatasetsListResponse) SetDatasets(datasets []*Dataset) {
	d.Datasets = datasets
	d.require(datasetsListResponseFieldDatasets)
}

func (d *DatasetsListResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler DatasetsListResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*d = DatasetsListResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *d)
	if err != nil {
		return err
	}
	d.extraProperties = extraProperties
	d.rawJSON = json.RawMessage(data)
	return nil
}

func (d *DatasetsListResponse) MarshalJSON() ([]byte, error) {
	type embed DatasetsListResponse
	var marshaler = struct {
		embed
	}{
		embed: embed(*d),
	}
	explicitMarshaler := internal.HandleExplicitFields(marshaler, d.explicitFields)
	return json.Marshal(explicitMarshaler)
}

func (d *DatasetsListResponse) String() string {
	if len(d.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(d.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(d); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", d)
}
