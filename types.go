// Code generated by Fern. DO NOT EDIT.

package api

import (
	json "encoding/json"
	fmt "fmt"
	internal "github.com/cohere-ai/cohere-go/v3/internal"
)

type ChatRequest struct {
	// Pass text/event-stream to receive the streamed response as server-sent events. The default is `\n` delimited events.
	Accepts *string `json:"-" url:"-"`
	// Text input for the model to respond to.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Message string `json:"message" url:"-"`
	// The name of a compatible [Cohere model](https://docs.cohere.com/docs/models) or the ID of a [fine-tuned](https://docs.cohere.com/docs/chat-fine-tuning) model.
	//
	// Compatible Deployments: Cohere Platform, Private Deployments
	Model *string `json:"model,omitempty" url:"-"`
	// Defaults to `false`.
	//
	// When `true`, the response will be a JSON stream of events. The final event will contain the complete response, and will have an `event_type` of `"stream-end"`.
	//
	// Streaming is beneficial for user interfaces that render the contents of the response piece by piece, as it gets generated.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	// When specified, the default Cohere preamble will be replaced with the provided one. Preambles are a part of the prompt used to adjust the model's overall behavior and conversation style, and use the `SYSTEM` role.
	//
	// The `SYSTEM` role is also used for the contents of the optional `chat_history=` parameter. When used with the `chat_history=` parameter it adds content throughout a conversation. Conversely, when used with the `preamble=` parameter it adds content at the start of the conversation only.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Preamble *string `json:"preamble,omitempty" url:"-"`
	// A list of previous messages between the user and the model, giving the model conversational context for responding to the user's `message`.
	//
	// Each item represents a single message in the chat history, excluding the current user turn. It has two properties: `role` and `message`. The `role` identifies the sender (`CHATBOT`, `SYSTEM`, or `USER`), while the `message` contains the text content.
	//
	// The chat_history parameter should not be used for `SYSTEM` messages in most cases. Instead, to add a `SYSTEM` role message at the beginning of a conversation, the `preamble` parameter should be used.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	ChatHistory []*Message `json:"chat_history,omitempty" url:"-"`
	// An alternative to `chat_history`.
	//
	// Providing a `conversation_id` creates or resumes a persisted conversation with the specified ID. The ID can be any non empty string.
	//
	// Compatible Deployments: Cohere Platform
	ConversationId *string `json:"conversation_id,omitempty" url:"-"`
	// Defaults to `AUTO` when `connectors` are specified and `OFF` in all other cases.
	//
	// Dictates how the prompt will be constructed.
	//
	// With `prompt_truncation` set to "AUTO", some elements from `chat_history` and `documents` will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be changed and ranked by relevance.
	//
	// With `prompt_truncation` set to "AUTO_PRESERVE_ORDER", some elements from `chat_history` and `documents` will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be preserved as they are inputted into the API.
	//
	// With `prompt_truncation` set to "OFF", no elements will be dropped. If the sum of the inputs exceeds the model's context length limit, a `TooManyTokens` error will be returned.
	//
	// Compatible Deployments:
	//   - AUTO: Cohere Platform Only
	//   - AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments
	PromptTruncation *ChatRequestPromptTruncation `json:"prompt_truncation,omitempty" url:"-"`
	// Accepts `{"id": "web-search"}`, and/or the `"id"` for a custom [connector](https://docs.cohere.com/docs/connectors), if you've [created](https://docs.cohere.com/v1/docs/creating-and-deploying-a-connector) one.
	//
	// When specified, the model's reply will be enriched with information found by querying each of the connectors (RAG).
	//
	// Compatible Deployments: Cohere Platform
	Connectors []*ChatConnector `json:"connectors,omitempty" url:"-"`
	// Defaults to `false`.
	//
	// When `true`, the response will only contain a list of generated search queries, but no search will take place, and no reply from the model to the user's `message` will be generated.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	SearchQueriesOnly *bool `json:"search_queries_only,omitempty" url:"-"`
	// A list of relevant documents that the model can cite to generate a more accurate reply. Each document is a string-string dictionary.
	//
	// Example:
	// ```
	// [
	//
	//	{ "title": "Tall penguins", "text": "Emperor penguins are the tallest." },
	//	{ "title": "Penguin habitats", "text": "Emperor penguins only live in Antarctica." },
	//
	// ]
	// ```
	//
	// Keys and values from each document will be serialized to a string and passed to the model. The resulting generation will include citations that reference some of these documents.
	//
	// Some suggested keys are "text", "author", and "date". For better generation quality, it is recommended to keep the total word count of the strings in the dictionary to under 300 words.
	//
	// An `id` field (string) can be optionally supplied to identify the document in the citations. This field will not be passed to the model.
	//
	// An `_excludes` field (array of strings) can be optionally supplied to omit some key-value pairs from being shown to the model. The omitted fields will still show up in the citation object. The "_excludes" field will not be passed to the model.
	//
	// See ['Document Mode'](https://docs.cohere.com/docs/retrieval-augmented-generation-rag#document-mode) in the guide for more information.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Documents []ChatDocument `json:"documents,omitempty" url:"-"`
	// Defaults to `"accurate"`.
	//
	// Dictates the approach taken to generating citations as part of the RAG flow by allowing the user to specify whether they want `"accurate"` results, `"fast"` results or no results.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	CitationQuality *ChatRequestCitationQuality `json:"citation_quality,omitempty" url:"-"`
	// Defaults to `0.3`.
	//
	// A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations, and higher temperatures mean more random generations.
	//
	// Randomness can be further maximized by increasing the  value of the `p` parameter.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Temperature *float64 `json:"temperature,omitempty" url:"-"`
	// The maximum number of tokens the model will generate as part of the response. Note: Setting a low value may result in incomplete generations.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	MaxTokens *int `json:"max_tokens,omitempty" url:"-"`
	// The maximum number of input tokens to send to the model. If not specified, `max_input_tokens` is the model's context length limit minus a small buffer.
	//
	// Input will be truncated according to the `prompt_truncation` parameter.
	//
	// Compatible Deployments: Cohere Platform
	MaxInputTokens *int `json:"max_input_tokens,omitempty" url:"-"`
	// Ensures only the top `k` most likely tokens are considered for generation at each step.
	// Defaults to `0`, min value of `0`, max value of `500`.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	K *int `json:"k,omitempty" url:"-"`
	// Ensures that only the most likely tokens, with total probability mass of `p`, are considered for generation at each step. If both `k` and `p` are enabled, `p` acts after `k`.
	// Defaults to `0.75`. min value of `0.01`, max value of `0.99`.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	P *float64 `json:"p,omitempty" url:"-"`
	// If specified, the backend will make a best effort to sample tokens
	// deterministically, such that repeated requests with the same
	// seed and parameters should return the same result. However,
	// determinism cannot be totally guaranteed.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Seed *int `json:"seed,omitempty" url:"-"`
	// A list of up to 5 strings that the model will use to stop generation. If the model generates a string that matches any of the strings in the list, it will stop generating tokens and return the generated text up to that point not including the stop sequence.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	StopSequences []string `json:"stop_sequences,omitempty" url:"-"`
	// Defaults to `0.0`, min value of `0.0`, max value of `1.0`.
	//
	// Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	FrequencyPenalty *float64 `json:"frequency_penalty,omitempty" url:"-"`
	// Defaults to `0.0`, min value of `0.0`, max value of `1.0`.
	//
	// Used to reduce repetitiveness of generated tokens. Similar to `frequency_penalty`, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	PresencePenalty *float64 `json:"presence_penalty,omitempty" url:"-"`
	// A list of available tools (functions) that the model may suggest invoking before producing a text response.
	//
	// When `tools` is passed (without `tool_results`), the `text` field in the response will be `""` and the `tool_calls` field in the response will be populated with a list of tool calls that need to be made. If no calls need to be made, the `tool_calls` array will be empty.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Tools []*Tool `json:"tools,omitempty" url:"-"`
	// A list of results from invoking tools recommended by the model in the previous chat turn. Results are used to produce a text response and will be referenced in citations. When using `tool_results`, `tools` must be passed as well.
	// Each tool_result contains information about how it was invoked, as well as a list of outputs in the form of dictionaries.
	//
	// **Note**: `outputs` must be a list of objects. If your tool returns a single object (eg `{"status": 200}`), make sure to wrap it in a list.
	// ```
	// tool_results = [
	//
	//	{
	//	  "call": {
	//	    "name": <tool name>,
	//	    "parameters": {
	//	      <param name>: <param value>
	//	    }
	//	  },
	//	  "outputs": [{
	//	    <key>: <value>
	//	  }]
	//	},
	//	...
	//
	// ]
	// ```
	// **Note**: Chat calls with `tool_results` should not be included in the Chat history to avoid duplication of the message text.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	ToolResults []*ToolResult `json:"tool_results,omitempty" url:"-"`
	// Forces the chat to be single step. Defaults to `false`.
	ForceSingleStep *bool           `json:"force_single_step,omitempty" url:"-"`
	ResponseFormat  *ResponseFormat `json:"response_format,omitempty" url:"-"`
	// Used to select the [safety instruction](https://docs.cohere.com/docs/safety-modes) inserted into the prompt. Defaults to `CONTEXTUAL`.
	// When `NONE` is specified, the safety instruction will be omitted.
	//
	// Safety modes are not yet configurable in combination with `tools`, `tool_results` and `documents` parameters.
	//
	// **Note**: This parameter is only compatible newer Cohere models, starting with [Command R 08-2024](https://docs.cohere.com/docs/command-r#august-2024-release) and [Command R+ 08-2024](https://docs.cohere.com/docs/command-r-plus#august-2024-release).
	//
	// **Note**: `command-r7b-12-2024` and newer models only support `"CONTEXTUAL"` and `"STRICT"` modes.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	SafetyMode *ChatRequestSafetyMode `json:"safety_mode,omitempty" url:"-"`
	stream     bool
}

func (c *ChatRequest) Stream() bool {
	return c.stream
}

func (c *ChatRequest) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatRequest
	var body unmarshaler
	if err := json.Unmarshal(data, &body); err != nil {
		return err
	}
	*c = ChatRequest(body)
	c.stream = false
	return nil
}

func (c *ChatRequest) MarshalJSON() ([]byte, error) {
	type embed ChatRequest
	var marshaler = struct {
		embed
		Stream bool `json:"stream"`
	}{
		embed:  embed(*c),
		Stream: false,
	}
	return json.Marshal(marshaler)
}

type ChatStreamRequest struct {
	// Pass text/event-stream to receive the streamed response as server-sent events. The default is `\n` delimited events.
	Accepts *string `json:"-" url:"-"`
	// Text input for the model to respond to.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Message string `json:"message" url:"-"`
	// The name of a compatible [Cohere model](https://docs.cohere.com/docs/models) or the ID of a [fine-tuned](https://docs.cohere.com/docs/chat-fine-tuning) model.
	//
	// Compatible Deployments: Cohere Platform, Private Deployments
	Model *string `json:"model,omitempty" url:"-"`
	// Defaults to `false`.
	//
	// When `true`, the response will be a JSON stream of events. The final event will contain the complete response, and will have an `event_type` of `"stream-end"`.
	//
	// Streaming is beneficial for user interfaces that render the contents of the response piece by piece, as it gets generated.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	// When specified, the default Cohere preamble will be replaced with the provided one. Preambles are a part of the prompt used to adjust the model's overall behavior and conversation style, and use the `SYSTEM` role.
	//
	// The `SYSTEM` role is also used for the contents of the optional `chat_history=` parameter. When used with the `chat_history=` parameter it adds content throughout a conversation. Conversely, when used with the `preamble=` parameter it adds content at the start of the conversation only.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Preamble *string `json:"preamble,omitempty" url:"-"`
	// A list of previous messages between the user and the model, giving the model conversational context for responding to the user's `message`.
	//
	// Each item represents a single message in the chat history, excluding the current user turn. It has two properties: `role` and `message`. The `role` identifies the sender (`CHATBOT`, `SYSTEM`, or `USER`), while the `message` contains the text content.
	//
	// The chat_history parameter should not be used for `SYSTEM` messages in most cases. Instead, to add a `SYSTEM` role message at the beginning of a conversation, the `preamble` parameter should be used.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	ChatHistory []*Message `json:"chat_history,omitempty" url:"-"`
	// An alternative to `chat_history`.
	//
	// Providing a `conversation_id` creates or resumes a persisted conversation with the specified ID. The ID can be any non empty string.
	//
	// Compatible Deployments: Cohere Platform
	ConversationId *string `json:"conversation_id,omitempty" url:"-"`
	// Defaults to `AUTO` when `connectors` are specified and `OFF` in all other cases.
	//
	// Dictates how the prompt will be constructed.
	//
	// With `prompt_truncation` set to "AUTO", some elements from `chat_history` and `documents` will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be changed and ranked by relevance.
	//
	// With `prompt_truncation` set to "AUTO_PRESERVE_ORDER", some elements from `chat_history` and `documents` will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be preserved as they are inputted into the API.
	//
	// With `prompt_truncation` set to "OFF", no elements will be dropped. If the sum of the inputs exceeds the model's context length limit, a `TooManyTokens` error will be returned.
	//
	// Compatible Deployments:
	//   - AUTO: Cohere Platform Only
	//   - AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments
	PromptTruncation *ChatStreamRequestPromptTruncation `json:"prompt_truncation,omitempty" url:"-"`
	// Accepts `{"id": "web-search"}`, and/or the `"id"` for a custom [connector](https://docs.cohere.com/docs/connectors), if you've [created](https://docs.cohere.com/v1/docs/creating-and-deploying-a-connector) one.
	//
	// When specified, the model's reply will be enriched with information found by querying each of the connectors (RAG).
	//
	// Compatible Deployments: Cohere Platform
	Connectors []*ChatConnector `json:"connectors,omitempty" url:"-"`
	// Defaults to `false`.
	//
	// When `true`, the response will only contain a list of generated search queries, but no search will take place, and no reply from the model to the user's `message` will be generated.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	SearchQueriesOnly *bool `json:"search_queries_only,omitempty" url:"-"`
	// A list of relevant documents that the model can cite to generate a more accurate reply. Each document is a string-string dictionary.
	//
	// Example:
	// ```
	// [
	//
	//	{ "title": "Tall penguins", "text": "Emperor penguins are the tallest." },
	//	{ "title": "Penguin habitats", "text": "Emperor penguins only live in Antarctica." },
	//
	// ]
	// ```
	//
	// Keys and values from each document will be serialized to a string and passed to the model. The resulting generation will include citations that reference some of these documents.
	//
	// Some suggested keys are "text", "author", and "date". For better generation quality, it is recommended to keep the total word count of the strings in the dictionary to under 300 words.
	//
	// An `id` field (string) can be optionally supplied to identify the document in the citations. This field will not be passed to the model.
	//
	// An `_excludes` field (array of strings) can be optionally supplied to omit some key-value pairs from being shown to the model. The omitted fields will still show up in the citation object. The "_excludes" field will not be passed to the model.
	//
	// See ['Document Mode'](https://docs.cohere.com/docs/retrieval-augmented-generation-rag#document-mode) in the guide for more information.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Documents []ChatDocument `json:"documents,omitempty" url:"-"`
	// Defaults to `"accurate"`.
	//
	// Dictates the approach taken to generating citations as part of the RAG flow by allowing the user to specify whether they want `"accurate"` results, `"fast"` results or no results.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	CitationQuality *ChatStreamRequestCitationQuality `json:"citation_quality,omitempty" url:"-"`
	// Defaults to `0.3`.
	//
	// A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations, and higher temperatures mean more random generations.
	//
	// Randomness can be further maximized by increasing the  value of the `p` parameter.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Temperature *float64 `json:"temperature,omitempty" url:"-"`
	// The maximum number of tokens the model will generate as part of the response. Note: Setting a low value may result in incomplete generations.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	MaxTokens *int `json:"max_tokens,omitempty" url:"-"`
	// The maximum number of input tokens to send to the model. If not specified, `max_input_tokens` is the model's context length limit minus a small buffer.
	//
	// Input will be truncated according to the `prompt_truncation` parameter.
	//
	// Compatible Deployments: Cohere Platform
	MaxInputTokens *int `json:"max_input_tokens,omitempty" url:"-"`
	// Ensures only the top `k` most likely tokens are considered for generation at each step.
	// Defaults to `0`, min value of `0`, max value of `500`.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	K *int `json:"k,omitempty" url:"-"`
	// Ensures that only the most likely tokens, with total probability mass of `p`, are considered for generation at each step. If both `k` and `p` are enabled, `p` acts after `k`.
	// Defaults to `0.75`. min value of `0.01`, max value of `0.99`.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	P *float64 `json:"p,omitempty" url:"-"`
	// If specified, the backend will make a best effort to sample tokens
	// deterministically, such that repeated requests with the same
	// seed and parameters should return the same result. However,
	// determinism cannot be totally guaranteed.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Seed *int `json:"seed,omitempty" url:"-"`
	// A list of up to 5 strings that the model will use to stop generation. If the model generates a string that matches any of the strings in the list, it will stop generating tokens and return the generated text up to that point not including the stop sequence.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	StopSequences []string `json:"stop_sequences,omitempty" url:"-"`
	// Defaults to `0.0`, min value of `0.0`, max value of `1.0`.
	//
	// Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	FrequencyPenalty *float64 `json:"frequency_penalty,omitempty" url:"-"`
	// Defaults to `0.0`, min value of `0.0`, max value of `1.0`.
	//
	// Used to reduce repetitiveness of generated tokens. Similar to `frequency_penalty`, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	PresencePenalty *float64 `json:"presence_penalty,omitempty" url:"-"`
	// A list of available tools (functions) that the model may suggest invoking before producing a text response.
	//
	// When `tools` is passed (without `tool_results`), the `text` field in the response will be `""` and the `tool_calls` field in the response will be populated with a list of tool calls that need to be made. If no calls need to be made, the `tool_calls` array will be empty.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Tools []*Tool `json:"tools,omitempty" url:"-"`
	// A list of results from invoking tools recommended by the model in the previous chat turn. Results are used to produce a text response and will be referenced in citations. When using `tool_results`, `tools` must be passed as well.
	// Each tool_result contains information about how it was invoked, as well as a list of outputs in the form of dictionaries.
	//
	// **Note**: `outputs` must be a list of objects. If your tool returns a single object (eg `{"status": 200}`), make sure to wrap it in a list.
	// ```
	// tool_results = [
	//
	//	{
	//	  "call": {
	//	    "name": <tool name>,
	//	    "parameters": {
	//	      <param name>: <param value>
	//	    }
	//	  },
	//	  "outputs": [{
	//	    <key>: <value>
	//	  }]
	//	},
	//	...
	//
	// ]
	// ```
	// **Note**: Chat calls with `tool_results` should not be included in the Chat history to avoid duplication of the message text.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	ToolResults []*ToolResult `json:"tool_results,omitempty" url:"-"`
	// Forces the chat to be single step. Defaults to `false`.
	ForceSingleStep *bool           `json:"force_single_step,omitempty" url:"-"`
	ResponseFormat  *ResponseFormat `json:"response_format,omitempty" url:"-"`
	// Used to select the [safety instruction](https://docs.cohere.com/docs/safety-modes) inserted into the prompt. Defaults to `CONTEXTUAL`.
	// When `NONE` is specified, the safety instruction will be omitted.
	//
	// Safety modes are not yet configurable in combination with `tools`, `tool_results` and `documents` parameters.
	//
	// **Note**: This parameter is only compatible newer Cohere models, starting with [Command R 08-2024](https://docs.cohere.com/docs/command-r#august-2024-release) and [Command R+ 08-2024](https://docs.cohere.com/docs/command-r-plus#august-2024-release).
	//
	// **Note**: `command-r7b-12-2024` and newer models only support `"CONTEXTUAL"` and `"STRICT"` modes.
	//
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	SafetyMode *ChatStreamRequestSafetyMode `json:"safety_mode,omitempty" url:"-"`
	stream     bool
}

func (c *ChatStreamRequest) Stream() bool {
	return c.stream
}

func (c *ChatStreamRequest) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatStreamRequest
	var body unmarshaler
	if err := json.Unmarshal(data, &body); err != nil {
		return err
	}
	*c = ChatStreamRequest(body)
	c.stream = true
	return nil
}

func (c *ChatStreamRequest) MarshalJSON() ([]byte, error) {
	type embed ChatStreamRequest
	var marshaler = struct {
		embed
		Stream bool `json:"stream"`
	}{
		embed:  embed(*c),
		Stream: true,
	}
	return json.Marshal(marshaler)
}

type ClassifyRequest struct {
	// A list of up to 96 texts to be classified. Each one must be a non-empty string.
	// There is, however, no consistent, universal limit to the length a particular input can be. We perform classification on the first `x` tokens of each input, and `x` varies depending on which underlying model is powering classification. The maximum token length for each model is listed in the "max tokens" column [here](https://docs.cohere.com/docs/models).
	// Note: by default the `truncate` parameter is set to `END`, so tokens exceeding the limit will be automatically dropped. This behavior can be disabled by setting `truncate` to `NONE`, which will result in validation errors for longer texts.
	Inputs []string `json:"inputs,omitempty" url:"-"`
	// An array of examples to provide context to the model. Each example is a text string and its associated label/class. Each unique label requires at least 2 examples associated with it; the maximum number of examples is 2500, and each example has a maximum length of 512 tokens. The values should be structured as `{text: "...",label: "..."}`.
	// Note: [Fine-tuned Models](https://docs.cohere.com/docs/classify-fine-tuning) trained on classification examples don't require the `examples` parameter to be passed in explicitly.
	Examples []*ClassifyExample `json:"examples,omitempty" url:"-"`
	// ID of a [Fine-tuned](https://docs.cohere.com/v2/docs/classify-starting-the-training) Classify model
	Model *string `json:"model,omitempty" url:"-"`
	// The ID of a custom playground preset. You can create presets in the [playground](https://dashboard.cohere.com/playground/classify?model=large). If you use a preset, all other parameters become optional, and any included parameters will override the preset's parameters.
	Preset *string `json:"preset,omitempty" url:"-"`
	// One of `NONE|START|END` to specify how the API will handle inputs longer than the maximum token length.
	// Passing `START` will discard the start of the input. `END` will discard the end of the input. In both cases, input is discarded until the remaining input is exactly the maximum input token length for the model.
	// If `NONE` is selected, when the input exceeds the maximum input token length an error will be returned.
	Truncate *ClassifyRequestTruncate `json:"truncate,omitempty" url:"-"`
}

type DetokenizeRequest struct {
	// The list of tokens to be detokenized.
	Tokens []int `json:"tokens,omitempty" url:"-"`
	// An optional parameter to provide the model name. This will ensure that the detokenization is done by the tokenizer used by that model.
	Model string `json:"model" url:"-"`
}

type EmbedRequest struct {
	// An array of strings for the model to embed. Maximum number of texts per call is `96`.
	Texts []string `json:"texts,omitempty" url:"-"`
	// An array of image data URIs for the model to embed. Maximum number of images per call is `1`.
	//
	// The image must be a valid [data URI](https://developer.mozilla.org/en-US/docs/Web/URI/Schemes/data). The image must be in either `image/jpeg` or `image/png` format and has a maximum size of 5MB.
	//
	// Images are only supported with Embed v3.0 and newer models.
	Images []string `json:"images,omitempty" url:"-"`
	// ID of one of the available [Embedding models](https://docs.cohere.com/docs/cohere-embed).
	Model     *string         `json:"model,omitempty" url:"-"`
	InputType *EmbedInputType `json:"input_type,omitempty" url:"-"`
	// Specifies the types of embeddings you want to get back. Not required and default is None, which returns the Embed Floats response type. Can be one or more of the following types.
	//
	// * `"float"`: Use this when you want to get back the default float embeddings. Supported with all Embed models.
	// * `"int8"`: Use this when you want to get back signed int8 embeddings. Supported with Embed v3.0 and newer Embed models.
	// * `"uint8"`: Use this when you want to get back unsigned int8 embeddings. Supported with Embed v3.0 and newer Embed models.
	// * `"binary"`: Use this when you want to get back signed binary embeddings. Supported with Embed v3.0 and newer Embed models.
	// * `"ubinary"`: Use this when you want to get back unsigned binary embeddings. Supported with Embed v3.0 and newer Embed models.
	EmbeddingTypes []EmbeddingType `json:"embedding_types,omitempty" url:"-"`
	// One of `NONE|START|END` to specify how the API will handle inputs longer than the maximum token length.
	//
	// Passing `START` will discard the start of the input. `END` will discard the end of the input. In both cases, input is discarded until the remaining input is exactly the maximum input token length for the model.
	//
	// If `NONE` is selected, when the input exceeds the maximum input token length an error will be returned.
	Truncate *EmbedRequestTruncate `json:"truncate,omitempty" url:"-"`
}

type GenerateRequest struct {
	// The input text that serves as the starting point for generating the response.
	// Note: The prompt will be pre-processed and modified before reaching the model.
	Prompt string `json:"prompt" url:"-"`
	// The identifier of the model to generate with. Currently available models are `command` (default), `command-nightly` (experimental), `command-light`, and `command-light-nightly` (experimental).
	// Smaller, "light" models are faster, while larger models will perform better. [Custom models](https://docs.cohere.com/docs/training-custom-models) can also be supplied with their full ID.
	Model *string `json:"model,omitempty" url:"-"`
	// The maximum number of generations that will be returned. Defaults to `1`, min value of `1`, max value of `5`.
	NumGenerations *int `json:"num_generations,omitempty" url:"-"`
	// When `true`, the response will be a JSON stream of events. Streaming is beneficial for user interfaces that render the contents of the response piece by piece, as it gets generated.
	//
	// The final event will contain the complete response, and will contain an `is_finished` field set to `true`. The event will also contain a `finish_reason`, which can be one of the following:
	// - `COMPLETE` - the model sent back a finished reply
	// - `MAX_TOKENS` - the reply was cut off because the model reached the maximum number of tokens for its context length
	// - `ERROR` - something went wrong when generating the reply
	// - `ERROR_TOXIC` - the model generated a reply that was deemed toxic
	// The maximum number of tokens the model will generate as part of the response. Note: Setting a low value may result in incomplete generations.
	//
	// This parameter is off by default, and if it's not specified, the model will continue generating until it emits an EOS completion token. See [BPE Tokens](/bpe-tokens-wiki) for more details.
	//
	// Can only be set to `0` if `return_likelihoods` is set to `ALL` to get the likelihood of the prompt.
	MaxTokens *int `json:"max_tokens,omitempty" url:"-"`
	// One of `NONE|START|END` to specify how the API will handle inputs longer than the maximum token length.
	//
	// Passing `START` will discard the start of the input. `END` will discard the end of the input. In both cases, input is discarded until the remaining input is exactly the maximum input token length for the model.
	//
	// If `NONE` is selected, when the input exceeds the maximum input token length an error will be returned.
	Truncate *GenerateRequestTruncate `json:"truncate,omitempty" url:"-"`
	// A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations. See [Temperature](/temperature-wiki) for more details.
	// Defaults to `0.75`, min value of `0.0`, max value of `5.0`.
	Temperature *float64 `json:"temperature,omitempty" url:"-"`
	// If specified, the backend will make a best effort to sample tokens
	// deterministically, such that repeated requests with the same
	// seed and parameters should return the same result. However,
	// determinism cannot be totally guaranteed.
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Seed *int `json:"seed,omitempty" url:"-"`
	// Identifier of a custom preset. A preset is a combination of parameters, such as prompt, temperature etc. You can create presets in the [playground](https://dashboard.cohere.com/playground/generate).
	// When a preset is specified, the `prompt` parameter becomes optional, and any included parameters will override the preset's parameters.
	Preset *string `json:"preset,omitempty" url:"-"`
	// The generated text will be cut at the beginning of the earliest occurrence of an end sequence. The sequence will be excluded from the text.
	EndSequences []string `json:"end_sequences,omitempty" url:"-"`
	// The generated text will be cut at the end of the earliest occurrence of a stop sequence. The sequence will be included the text.
	StopSequences []string `json:"stop_sequences,omitempty" url:"-"`
	// Ensures only the top `k` most likely tokens are considered for generation at each step.
	// Defaults to `0`, min value of `0`, max value of `500`.
	K *int `json:"k,omitempty" url:"-"`
	// Ensures that only the most likely tokens, with total probability mass of `p`, are considered for generation at each step. If both `k` and `p` are enabled, `p` acts after `k`.
	// Defaults to `0.75`. min value of `0.01`, max value of `0.99`.
	P *float64 `json:"p,omitempty" url:"-"`
	// Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.
	//
	// Using `frequency_penalty` in combination with `presence_penalty` is not supported on newer models.
	FrequencyPenalty *float64 `json:"frequency_penalty,omitempty" url:"-"`
	// Defaults to `0.0`, min value of `0.0`, max value of `1.0`.
	//
	// Can be used to reduce repetitiveness of generated tokens. Similar to `frequency_penalty`, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.
	//
	// Using `frequency_penalty` in combination with `presence_penalty` is not supported on newer models.
	PresencePenalty *float64 `json:"presence_penalty,omitempty" url:"-"`
	// One of `GENERATION|NONE` to specify how and if the token likelihoods are returned with the response. Defaults to `NONE`.
	//
	// If `GENERATION` is selected, the token likelihoods will only be provided for generated text.
	//
	// WARNING: `ALL` is deprecated, and will be removed in a future release.
	ReturnLikelihoods *GenerateRequestReturnLikelihoods `json:"return_likelihoods,omitempty" url:"-"`
	// When enabled, the user's prompt will be sent to the model without any pre-processing.
	RawPrompting *bool `json:"raw_prompting,omitempty" url:"-"`
	stream       bool
}

func (g *GenerateRequest) Stream() bool {
	return g.stream
}

func (g *GenerateRequest) UnmarshalJSON(data []byte) error {
	type unmarshaler GenerateRequest
	var body unmarshaler
	if err := json.Unmarshal(data, &body); err != nil {
		return err
	}
	*g = GenerateRequest(body)
	g.stream = false
	return nil
}

func (g *GenerateRequest) MarshalJSON() ([]byte, error) {
	type embed GenerateRequest
	var marshaler = struct {
		embed
		Stream bool `json:"stream"`
	}{
		embed:  embed(*g),
		Stream: false,
	}
	return json.Marshal(marshaler)
}

type GenerateStreamRequest struct {
	// The input text that serves as the starting point for generating the response.
	// Note: The prompt will be pre-processed and modified before reaching the model.
	Prompt string `json:"prompt" url:"-"`
	// The identifier of the model to generate with. Currently available models are `command` (default), `command-nightly` (experimental), `command-light`, and `command-light-nightly` (experimental).
	// Smaller, "light" models are faster, while larger models will perform better. [Custom models](https://docs.cohere.com/docs/training-custom-models) can also be supplied with their full ID.
	Model *string `json:"model,omitempty" url:"-"`
	// The maximum number of generations that will be returned. Defaults to `1`, min value of `1`, max value of `5`.
	NumGenerations *int `json:"num_generations,omitempty" url:"-"`
	// When `true`, the response will be a JSON stream of events. Streaming is beneficial for user interfaces that render the contents of the response piece by piece, as it gets generated.
	//
	// The final event will contain the complete response, and will contain an `is_finished` field set to `true`. The event will also contain a `finish_reason`, which can be one of the following:
	// - `COMPLETE` - the model sent back a finished reply
	// - `MAX_TOKENS` - the reply was cut off because the model reached the maximum number of tokens for its context length
	// - `ERROR` - something went wrong when generating the reply
	// - `ERROR_TOXIC` - the model generated a reply that was deemed toxic
	// The maximum number of tokens the model will generate as part of the response. Note: Setting a low value may result in incomplete generations.
	//
	// This parameter is off by default, and if it's not specified, the model will continue generating until it emits an EOS completion token. See [BPE Tokens](/bpe-tokens-wiki) for more details.
	//
	// Can only be set to `0` if `return_likelihoods` is set to `ALL` to get the likelihood of the prompt.
	MaxTokens *int `json:"max_tokens,omitempty" url:"-"`
	// One of `NONE|START|END` to specify how the API will handle inputs longer than the maximum token length.
	//
	// Passing `START` will discard the start of the input. `END` will discard the end of the input. In both cases, input is discarded until the remaining input is exactly the maximum input token length for the model.
	//
	// If `NONE` is selected, when the input exceeds the maximum input token length an error will be returned.
	Truncate *GenerateStreamRequestTruncate `json:"truncate,omitempty" url:"-"`
	// A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations. See [Temperature](/temperature-wiki) for more details.
	// Defaults to `0.75`, min value of `0.0`, max value of `5.0`.
	Temperature *float64 `json:"temperature,omitempty" url:"-"`
	// If specified, the backend will make a best effort to sample tokens
	// deterministically, such that repeated requests with the same
	// seed and parameters should return the same result. However,
	// determinism cannot be totally guaranteed.
	// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
	Seed *int `json:"seed,omitempty" url:"-"`
	// Identifier of a custom preset. A preset is a combination of parameters, such as prompt, temperature etc. You can create presets in the [playground](https://dashboard.cohere.com/playground/generate).
	// When a preset is specified, the `prompt` parameter becomes optional, and any included parameters will override the preset's parameters.
	Preset *string `json:"preset,omitempty" url:"-"`
	// The generated text will be cut at the beginning of the earliest occurrence of an end sequence. The sequence will be excluded from the text.
	EndSequences []string `json:"end_sequences,omitempty" url:"-"`
	// The generated text will be cut at the end of the earliest occurrence of a stop sequence. The sequence will be included the text.
	StopSequences []string `json:"stop_sequences,omitempty" url:"-"`
	// Ensures only the top `k` most likely tokens are considered for generation at each step.
	// Defaults to `0`, min value of `0`, max value of `500`.
	K *int `json:"k,omitempty" url:"-"`
	// Ensures that only the most likely tokens, with total probability mass of `p`, are considered for generation at each step. If both `k` and `p` are enabled, `p` acts after `k`.
	// Defaults to `0.75`. min value of `0.01`, max value of `0.99`.
	P *float64 `json:"p,omitempty" url:"-"`
	// Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.
	//
	// Using `frequency_penalty` in combination with `presence_penalty` is not supported on newer models.
	FrequencyPenalty *float64 `json:"frequency_penalty,omitempty" url:"-"`
	// Defaults to `0.0`, min value of `0.0`, max value of `1.0`.
	//
	// Can be used to reduce repetitiveness of generated tokens. Similar to `frequency_penalty`, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.
	//
	// Using `frequency_penalty` in combination with `presence_penalty` is not supported on newer models.
	PresencePenalty *float64 `json:"presence_penalty,omitempty" url:"-"`
	// One of `GENERATION|NONE` to specify how and if the token likelihoods are returned with the response. Defaults to `NONE`.
	//
	// If `GENERATION` is selected, the token likelihoods will only be provided for generated text.
	//
	// WARNING: `ALL` is deprecated, and will be removed in a future release.
	ReturnLikelihoods *GenerateStreamRequestReturnLikelihoods `json:"return_likelihoods,omitempty" url:"-"`
	// When enabled, the user's prompt will be sent to the model without any pre-processing.
	RawPrompting *bool `json:"raw_prompting,omitempty" url:"-"`
	stream       bool
}

func (g *GenerateStreamRequest) Stream() bool {
	return g.stream
}

func (g *GenerateStreamRequest) UnmarshalJSON(data []byte) error {
	type unmarshaler GenerateStreamRequest
	var body unmarshaler
	if err := json.Unmarshal(data, &body); err != nil {
		return err
	}
	*g = GenerateStreamRequest(body)
	g.stream = true
	return nil
}

func (g *GenerateStreamRequest) MarshalJSON() ([]byte, error) {
	type embed GenerateStreamRequest
	var marshaler = struct {
		embed
		Stream bool `json:"stream"`
	}{
		embed:  embed(*g),
		Stream: true,
	}
	return json.Marshal(marshaler)
}

type RerankRequest struct {
	// The identifier of the model to use, eg `rerank-v3.5`.
	Model *string `json:"model,omitempty" url:"-"`
	// The search query
	Query string `json:"query" url:"-"`
	// A list of document objects or strings to rerank.
	// If a document is provided the text fields is required and all other fields will be preserved in the response.
	//
	// The total max chunks (length of documents * max_chunks_per_doc) must be less than 10000.
	//
	// We recommend a maximum of 1,000 documents for optimal endpoint performance.
	Documents []*RerankRequestDocumentsItem `json:"documents,omitempty" url:"-"`
	// The number of most relevant documents or indices to return, defaults to the length of the documents
	TopN *int `json:"top_n,omitempty" url:"-"`
	// If a JSON object is provided, you can specify which keys you would like to have considered for reranking. The model will rerank based on order of the fields passed in (i.e. rank_fields=['title','author','text'] will rerank using the values in title, author, text  sequentially. If the length of title, author, and text exceeds the context length of the model, the chunking will not re-consider earlier fields). If not provided, the model will use the default text field for ranking.
	RankFields []string `json:"rank_fields,omitempty" url:"-"`
	// - If false, returns results without the doc text - the api will return a list of {index, relevance score} where index is inferred from the list passed into the request.
	// - If true, returns results with the doc text passed in - the api will return an ordered list of {index, text, relevance score} where index + text refers to the list passed into the request.
	ReturnDocuments *bool `json:"return_documents,omitempty" url:"-"`
	// The maximum number of chunks to produce internally from a document
	MaxChunksPerDoc *int `json:"max_chunks_per_doc,omitempty" url:"-"`
}

type SummarizeRequest struct {
	// The text to generate a summary for. Can be up to 100,000 characters long. Currently the only supported language is English.
	Text string `json:"text" url:"-"`
	// One of `short`, `medium`, `long`, or `auto` defaults to `auto`. Indicates the approximate length of the summary. If `auto` is selected, the best option will be picked based on the input text.
	Length *SummarizeRequestLength `json:"length,omitempty" url:"-"`
	// One of `paragraph`, `bullets`, or `auto`, defaults to `auto`. Indicates the style in which the summary will be delivered - in a free form paragraph or in bullet points. If `auto` is selected, the best option will be picked based on the input text.
	Format *SummarizeRequestFormat `json:"format,omitempty" url:"-"`
	// The identifier of the model to generate the summary with. Currently available models are `command` (default), `command-nightly` (experimental), `command-light`, and `command-light-nightly` (experimental). Smaller, "light" models are faster, while larger models will perform better.
	Model *string `json:"model,omitempty" url:"-"`
	// One of `low`, `medium`, `high`, or `auto`, defaults to `auto`. Controls how close to the original text the summary is. `high` extractiveness summaries will lean towards reusing sentences verbatim, while `low` extractiveness summaries will tend to paraphrase more. If `auto` is selected, the best option will be picked based on the input text.
	Extractiveness *SummarizeRequestExtractiveness `json:"extractiveness,omitempty" url:"-"`
	// Ranges from 0 to 5. Controls the randomness of the output. Lower values tend to generate more “predictable” output, while higher values tend to generate more “creative” output. The sweet spot is typically between 0 and 1.
	Temperature *float64 `json:"temperature,omitempty" url:"-"`
	// A free-form instruction for modifying how the summaries get generated. Should complete the sentence "Generate a summary _". Eg. "focusing on the next steps" or "written by Yoda"
	AdditionalCommand *string `json:"additional_command,omitempty" url:"-"`
}

type TokenizeRequest struct {
	// The string to be tokenized, the minimum text length is 1 character, and the maximum text length is 65536 characters.
	Text string `json:"text" url:"-"`
	// The input will be tokenized by the tokenizer that is used by this model.
	Model string `json:"model" url:"-"`
}

type ApiMeta struct {
	ApiVersion  *ApiMetaApiVersion  `json:"api_version,omitempty" url:"api_version,omitempty"`
	BilledUnits *ApiMetaBilledUnits `json:"billed_units,omitempty" url:"billed_units,omitempty"`
	Tokens      *ApiMetaTokens      `json:"tokens,omitempty" url:"tokens,omitempty"`
	Warnings    []string            `json:"warnings,omitempty" url:"warnings,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (a *ApiMeta) GetApiVersion() *ApiMetaApiVersion {
	if a == nil {
		return nil
	}
	return a.ApiVersion
}

func (a *ApiMeta) GetBilledUnits() *ApiMetaBilledUnits {
	if a == nil {
		return nil
	}
	return a.BilledUnits
}

func (a *ApiMeta) GetTokens() *ApiMetaTokens {
	if a == nil {
		return nil
	}
	return a.Tokens
}

func (a *ApiMeta) GetWarnings() []string {
	if a == nil {
		return nil
	}
	return a.Warnings
}

func (a *ApiMeta) GetExtraProperties() map[string]interface{} {
	return a.extraProperties
}

func (a *ApiMeta) UnmarshalJSON(data []byte) error {
	type unmarshaler ApiMeta
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*a = ApiMeta(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *a)
	if err != nil {
		return err
	}
	a.extraProperties = extraProperties
	a.rawJSON = json.RawMessage(data)
	return nil
}

func (a *ApiMeta) String() string {
	if len(a.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(a.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(a); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", a)
}

type ApiMetaApiVersion struct {
	Version        string `json:"version" url:"version"`
	IsDeprecated   *bool  `json:"is_deprecated,omitempty" url:"is_deprecated,omitempty"`
	IsExperimental *bool  `json:"is_experimental,omitempty" url:"is_experimental,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (a *ApiMetaApiVersion) GetVersion() string {
	if a == nil {
		return ""
	}
	return a.Version
}

func (a *ApiMetaApiVersion) GetIsDeprecated() *bool {
	if a == nil {
		return nil
	}
	return a.IsDeprecated
}

func (a *ApiMetaApiVersion) GetIsExperimental() *bool {
	if a == nil {
		return nil
	}
	return a.IsExperimental
}

func (a *ApiMetaApiVersion) GetExtraProperties() map[string]interface{} {
	return a.extraProperties
}

func (a *ApiMetaApiVersion) UnmarshalJSON(data []byte) error {
	type unmarshaler ApiMetaApiVersion
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*a = ApiMetaApiVersion(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *a)
	if err != nil {
		return err
	}
	a.extraProperties = extraProperties
	a.rawJSON = json.RawMessage(data)
	return nil
}

func (a *ApiMetaApiVersion) String() string {
	if len(a.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(a.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(a); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", a)
}

type ApiMetaBilledUnits struct {
	// The number of billed images.
	Images *float64 `json:"images,omitempty" url:"images,omitempty"`
	// The number of billed input tokens.
	InputTokens *float64 `json:"input_tokens,omitempty" url:"input_tokens,omitempty"`
	// The number of billed output tokens.
	OutputTokens *float64 `json:"output_tokens,omitempty" url:"output_tokens,omitempty"`
	// The number of billed search units.
	SearchUnits *float64 `json:"search_units,omitempty" url:"search_units,omitempty"`
	// The number of billed classifications units.
	Classifications *float64 `json:"classifications,omitempty" url:"classifications,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (a *ApiMetaBilledUnits) GetImages() *float64 {
	if a == nil {
		return nil
	}
	return a.Images
}

func (a *ApiMetaBilledUnits) GetInputTokens() *float64 {
	if a == nil {
		return nil
	}
	return a.InputTokens
}

func (a *ApiMetaBilledUnits) GetOutputTokens() *float64 {
	if a == nil {
		return nil
	}
	return a.OutputTokens
}

func (a *ApiMetaBilledUnits) GetSearchUnits() *float64 {
	if a == nil {
		return nil
	}
	return a.SearchUnits
}

func (a *ApiMetaBilledUnits) GetClassifications() *float64 {
	if a == nil {
		return nil
	}
	return a.Classifications
}

func (a *ApiMetaBilledUnits) GetExtraProperties() map[string]interface{} {
	return a.extraProperties
}

func (a *ApiMetaBilledUnits) UnmarshalJSON(data []byte) error {
	type unmarshaler ApiMetaBilledUnits
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*a = ApiMetaBilledUnits(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *a)
	if err != nil {
		return err
	}
	a.extraProperties = extraProperties
	a.rawJSON = json.RawMessage(data)
	return nil
}

func (a *ApiMetaBilledUnits) String() string {
	if len(a.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(a.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(a); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", a)
}

type ApiMetaTokens struct {
	// The number of tokens used as input to the model.
	InputTokens *float64 `json:"input_tokens,omitempty" url:"input_tokens,omitempty"`
	// The number of tokens produced by the model.
	OutputTokens *float64 `json:"output_tokens,omitempty" url:"output_tokens,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (a *ApiMetaTokens) GetInputTokens() *float64 {
	if a == nil {
		return nil
	}
	return a.InputTokens
}

func (a *ApiMetaTokens) GetOutputTokens() *float64 {
	if a == nil {
		return nil
	}
	return a.OutputTokens
}

func (a *ApiMetaTokens) GetExtraProperties() map[string]interface{} {
	return a.extraProperties
}

func (a *ApiMetaTokens) UnmarshalJSON(data []byte) error {
	type unmarshaler ApiMetaTokens
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*a = ApiMetaTokens(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *a)
	if err != nil {
		return err
	}
	a.extraProperties = extraProperties
	a.rawJSON = json.RawMessage(data)
	return nil
}

func (a *ApiMetaTokens) String() string {
	if len(a.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(a.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(a); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", a)
}

// A section of the generated reply which cites external knowledge.
type ChatCitation struct {
	// The index of text that the citation starts at, counting from zero. For example, a generation of `Hello, world!` with a citation on `world` would have a start value of `7`. This is because the citation starts at `w`, which is the seventh character.
	Start int `json:"start" url:"start"`
	// The index of text that the citation ends after, counting from zero. For example, a generation of `Hello, world!` with a citation on `world` would have an end value of `11`. This is because the citation ends after `d`, which is the eleventh character.
	End int `json:"end" url:"end"`
	// The text of the citation. For example, a generation of `Hello, world!` with a citation of `world` would have a text value of `world`.
	Text string `json:"text" url:"text"`
	// Identifiers of documents cited by this section of the generated reply.
	DocumentIds []string `json:"document_ids" url:"document_ids"`
	// The type of citation which indicates what part of the response the citation is for.
	Type *ChatCitationType `json:"type,omitempty" url:"type,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatCitation) GetStart() int {
	if c == nil {
		return 0
	}
	return c.Start
}

func (c *ChatCitation) GetEnd() int {
	if c == nil {
		return 0
	}
	return c.End
}

func (c *ChatCitation) GetText() string {
	if c == nil {
		return ""
	}
	return c.Text
}

func (c *ChatCitation) GetDocumentIds() []string {
	if c == nil {
		return nil
	}
	return c.DocumentIds
}

func (c *ChatCitation) GetType() *ChatCitationType {
	if c == nil {
		return nil
	}
	return c.Type
}

func (c *ChatCitation) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatCitation) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatCitation
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatCitation(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatCitation) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ChatCitationGenerationEvent struct {
	// Citations for the generated reply.
	Citations []*ChatCitation `json:"citations" url:"citations"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatCitationGenerationEvent) GetCitations() []*ChatCitation {
	if c == nil {
		return nil
	}
	return c.Citations
}

func (c *ChatCitationGenerationEvent) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatCitationGenerationEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatCitationGenerationEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatCitationGenerationEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatCitationGenerationEvent) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

// The type of citation which indicates what part of the response the citation is for.
type ChatCitationType string

const (
	ChatCitationTypeTextContent ChatCitationType = "TEXT_CONTENT"
	ChatCitationTypePlan        ChatCitationType = "PLAN"
)

func NewChatCitationTypeFromString(s string) (ChatCitationType, error) {
	switch s {
	case "TEXT_CONTENT":
		return ChatCitationTypeTextContent, nil
	case "PLAN":
		return ChatCitationTypePlan, nil
	}
	var t ChatCitationType
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (c ChatCitationType) Ptr() *ChatCitationType {
	return &c
}

// The connector used for fetching documents.
type ChatConnector struct {
	// The identifier of the connector.
	Id string `json:"id" url:"id"`
	// When specified, this user access token will be passed to the connector in the Authorization header instead of the Cohere generated one.
	UserAccessToken *string `json:"user_access_token,omitempty" url:"user_access_token,omitempty"`
	// Defaults to `false`.
	//
	// When `true`, the request will continue if this connector returned an error.
	ContinueOnFailure *bool `json:"continue_on_failure,omitempty" url:"continue_on_failure,omitempty"`
	// Provides the connector with different settings at request time. The key/value pairs of this object are specific to each connector.
	//
	// For example, the connector `web-search` supports the `site` option, which limits search results to the specified domain.
	Options map[string]interface{} `json:"options,omitempty" url:"options,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatConnector) GetId() string {
	if c == nil {
		return ""
	}
	return c.Id
}

func (c *ChatConnector) GetUserAccessToken() *string {
	if c == nil {
		return nil
	}
	return c.UserAccessToken
}

func (c *ChatConnector) GetContinueOnFailure() *bool {
	if c == nil {
		return nil
	}
	return c.ContinueOnFailure
}

func (c *ChatConnector) GetOptions() map[string]interface{} {
	if c == nil {
		return nil
	}
	return c.Options
}

func (c *ChatConnector) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatConnector) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatConnector
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatConnector(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatConnector) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ChatDebugEvent struct {
	Prompt *string `json:"prompt,omitempty" url:"prompt,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatDebugEvent) GetPrompt() *string {
	if c == nil {
		return nil
	}
	return c.Prompt
}

func (c *ChatDebugEvent) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatDebugEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatDebugEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatDebugEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatDebugEvent) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

// Relevant information that could be used by the model to generate a more accurate reply.
// The contents of each document are generally short (under 300 words), and are passed in the form of a
// dictionary of strings. Some suggested keys are "text", "author", "date". Both the key name and the value will be
// passed to the model.
type ChatDocument = map[string]string

// Represents a single message in the chat history, excluding the current user turn. It has two properties: `role` and `message`. The `role` identifies the sender (`CHATBOT`, `SYSTEM`, or `USER`), while the `message` contains the text content.
//
// The chat_history parameter should not be used for `SYSTEM` messages in most cases. Instead, to add a `SYSTEM` role message at the beginning of a conversation, the `preamble` parameter should be used.
type ChatMessage struct {
	// Contents of the chat message.
	Message   string      `json:"message" url:"message"`
	ToolCalls []*ToolCall `json:"tool_calls,omitempty" url:"tool_calls,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatMessage) GetMessage() string {
	if c == nil {
		return ""
	}
	return c.Message
}

func (c *ChatMessage) GetToolCalls() []*ToolCall {
	if c == nil {
		return nil
	}
	return c.ToolCalls
}

func (c *ChatMessage) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatMessage) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatMessage
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatMessage(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatMessage) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

// Defaults to `"accurate"`.
//
// Dictates the approach taken to generating citations as part of the RAG flow by allowing the user to specify whether they want `"accurate"` results, `"fast"` results or no results.
//
// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
type ChatRequestCitationQuality string

const (
	ChatRequestCitationQualityFast     ChatRequestCitationQuality = "fast"
	ChatRequestCitationQualityAccurate ChatRequestCitationQuality = "accurate"
	ChatRequestCitationQualityOff      ChatRequestCitationQuality = "off"
)

func NewChatRequestCitationQualityFromString(s string) (ChatRequestCitationQuality, error) {
	switch s {
	case "fast":
		return ChatRequestCitationQualityFast, nil
	case "accurate":
		return ChatRequestCitationQualityAccurate, nil
	case "off":
		return ChatRequestCitationQualityOff, nil
	}
	var t ChatRequestCitationQuality
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (c ChatRequestCitationQuality) Ptr() *ChatRequestCitationQuality {
	return &c
}

// Defaults to `AUTO` when `connectors` are specified and `OFF` in all other cases.
//
// Dictates how the prompt will be constructed.
//
// With `prompt_truncation` set to "AUTO", some elements from `chat_history` and `documents` will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be changed and ranked by relevance.
//
// With `prompt_truncation` set to "AUTO_PRESERVE_ORDER", some elements from `chat_history` and `documents` will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be preserved as they are inputted into the API.
//
// With `prompt_truncation` set to "OFF", no elements will be dropped. If the sum of the inputs exceeds the model's context length limit, a `TooManyTokens` error will be returned.
//
// Compatible Deployments:
//   - AUTO: Cohere Platform Only
//   - AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments
type ChatRequestPromptTruncation string

const (
	ChatRequestPromptTruncationOff               ChatRequestPromptTruncation = "OFF"
	ChatRequestPromptTruncationAuto              ChatRequestPromptTruncation = "AUTO"
	ChatRequestPromptTruncationAutoPreserveOrder ChatRequestPromptTruncation = "AUTO_PRESERVE_ORDER"
)

func NewChatRequestPromptTruncationFromString(s string) (ChatRequestPromptTruncation, error) {
	switch s {
	case "OFF":
		return ChatRequestPromptTruncationOff, nil
	case "AUTO":
		return ChatRequestPromptTruncationAuto, nil
	case "AUTO_PRESERVE_ORDER":
		return ChatRequestPromptTruncationAutoPreserveOrder, nil
	}
	var t ChatRequestPromptTruncation
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (c ChatRequestPromptTruncation) Ptr() *ChatRequestPromptTruncation {
	return &c
}

// Used to select the [safety instruction](https://docs.cohere.com/docs/safety-modes) inserted into the prompt. Defaults to `CONTEXTUAL`.
// When `NONE` is specified, the safety instruction will be omitted.
//
// Safety modes are not yet configurable in combination with `tools`, `tool_results` and `documents` parameters.
//
// **Note**: This parameter is only compatible newer Cohere models, starting with [Command R 08-2024](https://docs.cohere.com/docs/command-r#august-2024-release) and [Command R+ 08-2024](https://docs.cohere.com/docs/command-r-plus#august-2024-release).
//
// **Note**: `command-r7b-12-2024` and newer models only support `"CONTEXTUAL"` and `"STRICT"` modes.
//
// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
type ChatRequestSafetyMode string

const (
	ChatRequestSafetyModeContextual ChatRequestSafetyMode = "CONTEXTUAL"
	ChatRequestSafetyModeStrict     ChatRequestSafetyMode = "STRICT"
	ChatRequestSafetyModeNone       ChatRequestSafetyMode = "NONE"
)

func NewChatRequestSafetyModeFromString(s string) (ChatRequestSafetyMode, error) {
	switch s {
	case "CONTEXTUAL":
		return ChatRequestSafetyModeContextual, nil
	case "STRICT":
		return ChatRequestSafetyModeStrict, nil
	case "NONE":
		return ChatRequestSafetyModeNone, nil
	}
	var t ChatRequestSafetyMode
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (c ChatRequestSafetyMode) Ptr() *ChatRequestSafetyMode {
	return &c
}

type ChatSearchQueriesGenerationEvent struct {
	// Generated search queries, meant to be used as part of the RAG flow.
	SearchQueries []*ChatSearchQuery `json:"search_queries" url:"search_queries"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatSearchQueriesGenerationEvent) GetSearchQueries() []*ChatSearchQuery {
	if c == nil {
		return nil
	}
	return c.SearchQueries
}

func (c *ChatSearchQueriesGenerationEvent) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatSearchQueriesGenerationEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatSearchQueriesGenerationEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatSearchQueriesGenerationEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatSearchQueriesGenerationEvent) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

// The generated search query. Contains the text of the query and a unique identifier for the query.
type ChatSearchQuery struct {
	// The text of the search query.
	Text string `json:"text" url:"text"`
	// Unique identifier for the generated search query. Useful for submitting feedback.
	GenerationId string `json:"generation_id" url:"generation_id"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatSearchQuery) GetText() string {
	if c == nil {
		return ""
	}
	return c.Text
}

func (c *ChatSearchQuery) GetGenerationId() string {
	if c == nil {
		return ""
	}
	return c.GenerationId
}

func (c *ChatSearchQuery) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatSearchQuery) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatSearchQuery
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatSearchQuery(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatSearchQuery) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ChatSearchResult struct {
	SearchQuery *ChatSearchQuery `json:"search_query,omitempty" url:"search_query,omitempty"`
	// The connector from which this result comes from.
	Connector *ChatSearchResultConnector `json:"connector" url:"connector"`
	// Identifiers of documents found by this search query.
	DocumentIds []string `json:"document_ids" url:"document_ids"`
	// An error message if the search failed.
	ErrorMessage *string `json:"error_message,omitempty" url:"error_message,omitempty"`
	// Whether a chat request should continue or not if the request to this connector fails.
	ContinueOnFailure *bool `json:"continue_on_failure,omitempty" url:"continue_on_failure,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatSearchResult) GetSearchQuery() *ChatSearchQuery {
	if c == nil {
		return nil
	}
	return c.SearchQuery
}

func (c *ChatSearchResult) GetConnector() *ChatSearchResultConnector {
	if c == nil {
		return nil
	}
	return c.Connector
}

func (c *ChatSearchResult) GetDocumentIds() []string {
	if c == nil {
		return nil
	}
	return c.DocumentIds
}

func (c *ChatSearchResult) GetErrorMessage() *string {
	if c == nil {
		return nil
	}
	return c.ErrorMessage
}

func (c *ChatSearchResult) GetContinueOnFailure() *bool {
	if c == nil {
		return nil
	}
	return c.ContinueOnFailure
}

func (c *ChatSearchResult) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatSearchResult) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatSearchResult
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatSearchResult(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatSearchResult) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

// The connector used for fetching documents.
type ChatSearchResultConnector struct {
	// The identifier of the connector.
	Id string `json:"id" url:"id"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatSearchResultConnector) GetId() string {
	if c == nil {
		return ""
	}
	return c.Id
}

func (c *ChatSearchResultConnector) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatSearchResultConnector) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatSearchResultConnector
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatSearchResultConnector(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatSearchResultConnector) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ChatSearchResultsEvent struct {
	// Conducted searches and the ids of documents retrieved from each of them.
	SearchResults []*ChatSearchResult `json:"search_results,omitempty" url:"search_results,omitempty"`
	// Documents fetched from searches or provided by the user.
	Documents []ChatDocument `json:"documents,omitempty" url:"documents,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatSearchResultsEvent) GetSearchResults() []*ChatSearchResult {
	if c == nil {
		return nil
	}
	return c.SearchResults
}

func (c *ChatSearchResultsEvent) GetDocuments() []ChatDocument {
	if c == nil {
		return nil
	}
	return c.Documents
}

func (c *ChatSearchResultsEvent) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatSearchResultsEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatSearchResultsEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatSearchResultsEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatSearchResultsEvent) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ChatStreamEndEvent struct {
	// - `COMPLETE` - the model sent back a finished reply
	// - `ERROR_LIMIT` - the reply was cut off because the model reached the maximum number of tokens for its context length
	// - `MAX_TOKENS` - the reply was cut off because the model reached the maximum number of tokens specified by the max_tokens parameter
	// - `ERROR` - something went wrong when generating the reply
	// - `ERROR_TOXIC` - the model generated a reply that was deemed toxic
	FinishReason ChatStreamEndEventFinishReason `json:"finish_reason" url:"finish_reason"`
	// The consolidated response from the model. Contains the generated reply and all the other information streamed back in the previous events.
	Response *NonStreamedChatResponse `json:"response" url:"response"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatStreamEndEvent) GetFinishReason() ChatStreamEndEventFinishReason {
	if c == nil {
		return ""
	}
	return c.FinishReason
}

func (c *ChatStreamEndEvent) GetResponse() *NonStreamedChatResponse {
	if c == nil {
		return nil
	}
	return c.Response
}

func (c *ChatStreamEndEvent) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatStreamEndEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatStreamEndEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatStreamEndEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatStreamEndEvent) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

// - `COMPLETE` - the model sent back a finished reply
// - `ERROR_LIMIT` - the reply was cut off because the model reached the maximum number of tokens for its context length
// - `MAX_TOKENS` - the reply was cut off because the model reached the maximum number of tokens specified by the max_tokens parameter
// - `ERROR` - something went wrong when generating the reply
// - `ERROR_TOXIC` - the model generated a reply that was deemed toxic
type ChatStreamEndEventFinishReason string

const (
	ChatStreamEndEventFinishReasonComplete   ChatStreamEndEventFinishReason = "COMPLETE"
	ChatStreamEndEventFinishReasonErrorLimit ChatStreamEndEventFinishReason = "ERROR_LIMIT"
	ChatStreamEndEventFinishReasonMaxTokens  ChatStreamEndEventFinishReason = "MAX_TOKENS"
	ChatStreamEndEventFinishReasonError      ChatStreamEndEventFinishReason = "ERROR"
	ChatStreamEndEventFinishReasonErrorToxic ChatStreamEndEventFinishReason = "ERROR_TOXIC"
)

func NewChatStreamEndEventFinishReasonFromString(s string) (ChatStreamEndEventFinishReason, error) {
	switch s {
	case "COMPLETE":
		return ChatStreamEndEventFinishReasonComplete, nil
	case "ERROR_LIMIT":
		return ChatStreamEndEventFinishReasonErrorLimit, nil
	case "MAX_TOKENS":
		return ChatStreamEndEventFinishReasonMaxTokens, nil
	case "ERROR":
		return ChatStreamEndEventFinishReasonError, nil
	case "ERROR_TOXIC":
		return ChatStreamEndEventFinishReasonErrorToxic, nil
	}
	var t ChatStreamEndEventFinishReason
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (c ChatStreamEndEventFinishReason) Ptr() *ChatStreamEndEventFinishReason {
	return &c
}

type ChatStreamEvent struct {
	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatStreamEvent) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatStreamEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatStreamEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatStreamEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatStreamEvent) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

// Defaults to `"accurate"`.
//
// Dictates the approach taken to generating citations as part of the RAG flow by allowing the user to specify whether they want `"accurate"` results, `"fast"` results or no results.
//
// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
type ChatStreamRequestCitationQuality string

const (
	ChatStreamRequestCitationQualityFast     ChatStreamRequestCitationQuality = "fast"
	ChatStreamRequestCitationQualityAccurate ChatStreamRequestCitationQuality = "accurate"
	ChatStreamRequestCitationQualityOff      ChatStreamRequestCitationQuality = "off"
)

func NewChatStreamRequestCitationQualityFromString(s string) (ChatStreamRequestCitationQuality, error) {
	switch s {
	case "fast":
		return ChatStreamRequestCitationQualityFast, nil
	case "accurate":
		return ChatStreamRequestCitationQualityAccurate, nil
	case "off":
		return ChatStreamRequestCitationQualityOff, nil
	}
	var t ChatStreamRequestCitationQuality
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (c ChatStreamRequestCitationQuality) Ptr() *ChatStreamRequestCitationQuality {
	return &c
}

// Defaults to `AUTO` when `connectors` are specified and `OFF` in all other cases.
//
// Dictates how the prompt will be constructed.
//
// With `prompt_truncation` set to "AUTO", some elements from `chat_history` and `documents` will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be changed and ranked by relevance.
//
// With `prompt_truncation` set to "AUTO_PRESERVE_ORDER", some elements from `chat_history` and `documents` will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be preserved as they are inputted into the API.
//
// With `prompt_truncation` set to "OFF", no elements will be dropped. If the sum of the inputs exceeds the model's context length limit, a `TooManyTokens` error will be returned.
//
// Compatible Deployments:
//   - AUTO: Cohere Platform Only
//   - AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments
type ChatStreamRequestPromptTruncation string

const (
	ChatStreamRequestPromptTruncationOff               ChatStreamRequestPromptTruncation = "OFF"
	ChatStreamRequestPromptTruncationAuto              ChatStreamRequestPromptTruncation = "AUTO"
	ChatStreamRequestPromptTruncationAutoPreserveOrder ChatStreamRequestPromptTruncation = "AUTO_PRESERVE_ORDER"
)

func NewChatStreamRequestPromptTruncationFromString(s string) (ChatStreamRequestPromptTruncation, error) {
	switch s {
	case "OFF":
		return ChatStreamRequestPromptTruncationOff, nil
	case "AUTO":
		return ChatStreamRequestPromptTruncationAuto, nil
	case "AUTO_PRESERVE_ORDER":
		return ChatStreamRequestPromptTruncationAutoPreserveOrder, nil
	}
	var t ChatStreamRequestPromptTruncation
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (c ChatStreamRequestPromptTruncation) Ptr() *ChatStreamRequestPromptTruncation {
	return &c
}

// Used to select the [safety instruction](https://docs.cohere.com/docs/safety-modes) inserted into the prompt. Defaults to `CONTEXTUAL`.
// When `NONE` is specified, the safety instruction will be omitted.
//
// Safety modes are not yet configurable in combination with `tools`, `tool_results` and `documents` parameters.
//
// **Note**: This parameter is only compatible newer Cohere models, starting with [Command R 08-2024](https://docs.cohere.com/docs/command-r#august-2024-release) and [Command R+ 08-2024](https://docs.cohere.com/docs/command-r-plus#august-2024-release).
//
// **Note**: `command-r7b-12-2024` and newer models only support `"CONTEXTUAL"` and `"STRICT"` modes.
//
// Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments
type ChatStreamRequestSafetyMode string

const (
	ChatStreamRequestSafetyModeContextual ChatStreamRequestSafetyMode = "CONTEXTUAL"
	ChatStreamRequestSafetyModeStrict     ChatStreamRequestSafetyMode = "STRICT"
	ChatStreamRequestSafetyModeNone       ChatStreamRequestSafetyMode = "NONE"
)

func NewChatStreamRequestSafetyModeFromString(s string) (ChatStreamRequestSafetyMode, error) {
	switch s {
	case "CONTEXTUAL":
		return ChatStreamRequestSafetyModeContextual, nil
	case "STRICT":
		return ChatStreamRequestSafetyModeStrict, nil
	case "NONE":
		return ChatStreamRequestSafetyModeNone, nil
	}
	var t ChatStreamRequestSafetyMode
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (c ChatStreamRequestSafetyMode) Ptr() *ChatStreamRequestSafetyMode {
	return &c
}

type ChatStreamStartEvent struct {
	// Unique identifier for the generated reply. Useful for submitting feedback.
	GenerationId string `json:"generation_id" url:"generation_id"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatStreamStartEvent) GetGenerationId() string {
	if c == nil {
		return ""
	}
	return c.GenerationId
}

func (c *ChatStreamStartEvent) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatStreamStartEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatStreamStartEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatStreamStartEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatStreamStartEvent) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ChatTextGenerationEvent struct {
	// The next batch of text generated by the model.
	Text string `json:"text" url:"text"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatTextGenerationEvent) GetText() string {
	if c == nil {
		return ""
	}
	return c.Text
}

func (c *ChatTextGenerationEvent) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatTextGenerationEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatTextGenerationEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatTextGenerationEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatTextGenerationEvent) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ChatTextResponseFormat struct {
	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatTextResponseFormat) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatTextResponseFormat) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatTextResponseFormat
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatTextResponseFormat(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatTextResponseFormat) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ChatToolCallsChunkEvent struct {
	ToolCallDelta *ToolCallDelta `json:"tool_call_delta" url:"tool_call_delta"`
	Text          *string        `json:"text,omitempty" url:"text,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatToolCallsChunkEvent) GetToolCallDelta() *ToolCallDelta {
	if c == nil {
		return nil
	}
	return c.ToolCallDelta
}

func (c *ChatToolCallsChunkEvent) GetText() *string {
	if c == nil {
		return nil
	}
	return c.Text
}

func (c *ChatToolCallsChunkEvent) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatToolCallsChunkEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatToolCallsChunkEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatToolCallsChunkEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatToolCallsChunkEvent) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ChatToolCallsGenerationEvent struct {
	// The text generated related to the tool calls generated
	Text      *string     `json:"text,omitempty" url:"text,omitempty"`
	ToolCalls []*ToolCall `json:"tool_calls" url:"tool_calls"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatToolCallsGenerationEvent) GetText() *string {
	if c == nil {
		return nil
	}
	return c.Text
}

func (c *ChatToolCallsGenerationEvent) GetToolCalls() []*ToolCall {
	if c == nil {
		return nil
	}
	return c.ToolCalls
}

func (c *ChatToolCallsGenerationEvent) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatToolCallsGenerationEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatToolCallsGenerationEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatToolCallsGenerationEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatToolCallsGenerationEvent) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

// Represents tool result in the chat history.
type ChatToolMessage struct {
	ToolResults []*ToolResult `json:"tool_results,omitempty" url:"tool_results,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ChatToolMessage) GetToolResults() []*ToolResult {
	if c == nil {
		return nil
	}
	return c.ToolResults
}

func (c *ChatToolMessage) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ChatToolMessage) UnmarshalJSON(data []byte) error {
	type unmarshaler ChatToolMessage
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ChatToolMessage(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ChatToolMessage) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type CheckApiKeyResponse struct {
	Valid          bool    `json:"valid" url:"valid"`
	OrganizationId *string `json:"organization_id,omitempty" url:"organization_id,omitempty"`
	OwnerId        *string `json:"owner_id,omitempty" url:"owner_id,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *CheckApiKeyResponse) GetValid() bool {
	if c == nil {
		return false
	}
	return c.Valid
}

func (c *CheckApiKeyResponse) GetOrganizationId() *string {
	if c == nil {
		return nil
	}
	return c.OrganizationId
}

func (c *CheckApiKeyResponse) GetOwnerId() *string {
	if c == nil {
		return nil
	}
	return c.OwnerId
}

func (c *CheckApiKeyResponse) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *CheckApiKeyResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler CheckApiKeyResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = CheckApiKeyResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *CheckApiKeyResponse) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ClassifyExample struct {
	Text  *string `json:"text,omitempty" url:"text,omitempty"`
	Label *string `json:"label,omitempty" url:"label,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ClassifyExample) GetText() *string {
	if c == nil {
		return nil
	}
	return c.Text
}

func (c *ClassifyExample) GetLabel() *string {
	if c == nil {
		return nil
	}
	return c.Label
}

func (c *ClassifyExample) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ClassifyExample) UnmarshalJSON(data []byte) error {
	type unmarshaler ClassifyExample
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ClassifyExample(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ClassifyExample) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

// One of `NONE|START|END` to specify how the API will handle inputs longer than the maximum token length.
// Passing `START` will discard the start of the input. `END` will discard the end of the input. In both cases, input is discarded until the remaining input is exactly the maximum input token length for the model.
// If `NONE` is selected, when the input exceeds the maximum input token length an error will be returned.
type ClassifyRequestTruncate string

const (
	ClassifyRequestTruncateNone  ClassifyRequestTruncate = "NONE"
	ClassifyRequestTruncateStart ClassifyRequestTruncate = "START"
	ClassifyRequestTruncateEnd   ClassifyRequestTruncate = "END"
)

func NewClassifyRequestTruncateFromString(s string) (ClassifyRequestTruncate, error) {
	switch s {
	case "NONE":
		return ClassifyRequestTruncateNone, nil
	case "START":
		return ClassifyRequestTruncateStart, nil
	case "END":
		return ClassifyRequestTruncateEnd, nil
	}
	var t ClassifyRequestTruncate
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (c ClassifyRequestTruncate) Ptr() *ClassifyRequestTruncate {
	return &c
}

type ClassifyResponse struct {
	Id              *string                                `json:"id,omitempty" url:"id,omitempty"`
	Classifications []*ClassifyResponseClassificationsItem `json:"classifications,omitempty" url:"classifications,omitempty"`
	Meta            *ApiMeta                               `json:"meta,omitempty" url:"meta,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ClassifyResponse) GetId() *string {
	if c == nil {
		return nil
	}
	return c.Id
}

func (c *ClassifyResponse) GetClassifications() []*ClassifyResponseClassificationsItem {
	if c == nil {
		return nil
	}
	return c.Classifications
}

func (c *ClassifyResponse) GetMeta() *ApiMeta {
	if c == nil {
		return nil
	}
	return c.Meta
}

func (c *ClassifyResponse) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ClassifyResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler ClassifyResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ClassifyResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ClassifyResponse) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type ClassifyResponseClassificationsItem struct {
	Id *string `json:"id,omitempty" url:"id,omitempty"`
	// The input text that was classified
	Input *string `json:"input,omitempty" url:"input,omitempty"`
	// The predicted label for the associated query (only filled for single-label models)
	Prediction *string `json:"prediction,omitempty" url:"prediction,omitempty"`
	// An array containing the predicted labels for the associated query (only filled for single-label classification)
	Predictions []string `json:"predictions,omitempty" url:"predictions,omitempty"`
	// The confidence score for the top predicted class (only filled for single-label classification)
	Confidence *float64 `json:"confidence,omitempty" url:"confidence,omitempty"`
	// An array containing the confidence scores of all the predictions in the same order
	Confidences []float64 `json:"confidences,omitempty" url:"confidences,omitempty"`
	// A map containing each label and its confidence score according to the classifier. All the confidence scores add up to 1 for single-label classification. For multi-label classification the label confidences are independent of each other, so they don't have to sum up to 1.
	Labels map[string]*ClassifyResponseClassificationsItemLabelsValue `json:"labels,omitempty" url:"labels,omitempty"`
	// The type of classification performed
	ClassificationType *ClassifyResponseClassificationsItemClassificationType `json:"classification_type,omitempty" url:"classification_type,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ClassifyResponseClassificationsItem) GetId() *string {
	if c == nil {
		return nil
	}
	return c.Id
}

func (c *ClassifyResponseClassificationsItem) GetInput() *string {
	if c == nil {
		return nil
	}
	return c.Input
}

func (c *ClassifyResponseClassificationsItem) GetPrediction() *string {
	if c == nil {
		return nil
	}
	return c.Prediction
}

func (c *ClassifyResponseClassificationsItem) GetPredictions() []string {
	if c == nil {
		return nil
	}
	return c.Predictions
}

func (c *ClassifyResponseClassificationsItem) GetConfidence() *float64 {
	if c == nil {
		return nil
	}
	return c.Confidence
}

func (c *ClassifyResponseClassificationsItem) GetConfidences() []float64 {
	if c == nil {
		return nil
	}
	return c.Confidences
}

func (c *ClassifyResponseClassificationsItem) GetLabels() map[string]*ClassifyResponseClassificationsItemLabelsValue {
	if c == nil {
		return nil
	}
	return c.Labels
}

func (c *ClassifyResponseClassificationsItem) GetClassificationType() *ClassifyResponseClassificationsItemClassificationType {
	if c == nil {
		return nil
	}
	return c.ClassificationType
}

func (c *ClassifyResponseClassificationsItem) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ClassifyResponseClassificationsItem) UnmarshalJSON(data []byte) error {
	type unmarshaler ClassifyResponseClassificationsItem
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ClassifyResponseClassificationsItem(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ClassifyResponseClassificationsItem) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

// The type of classification performed
type ClassifyResponseClassificationsItemClassificationType string

const (
	ClassifyResponseClassificationsItemClassificationTypeSingleLabel ClassifyResponseClassificationsItemClassificationType = "single-label"
	ClassifyResponseClassificationsItemClassificationTypeMultiLabel  ClassifyResponseClassificationsItemClassificationType = "multi-label"
)

func NewClassifyResponseClassificationsItemClassificationTypeFromString(s string) (ClassifyResponseClassificationsItemClassificationType, error) {
	switch s {
	case "single-label":
		return ClassifyResponseClassificationsItemClassificationTypeSingleLabel, nil
	case "multi-label":
		return ClassifyResponseClassificationsItemClassificationTypeMultiLabel, nil
	}
	var t ClassifyResponseClassificationsItemClassificationType
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (c ClassifyResponseClassificationsItemClassificationType) Ptr() *ClassifyResponseClassificationsItemClassificationType {
	return &c
}

type ClassifyResponseClassificationsItemLabelsValue struct {
	Confidence *float64 `json:"confidence,omitempty" url:"confidence,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (c *ClassifyResponseClassificationsItemLabelsValue) GetConfidence() *float64 {
	if c == nil {
		return nil
	}
	return c.Confidence
}

func (c *ClassifyResponseClassificationsItemLabelsValue) GetExtraProperties() map[string]interface{} {
	return c.extraProperties
}

func (c *ClassifyResponseClassificationsItemLabelsValue) UnmarshalJSON(data []byte) error {
	type unmarshaler ClassifyResponseClassificationsItemLabelsValue
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*c = ClassifyResponseClassificationsItemLabelsValue(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *c)
	if err != nil {
		return err
	}
	c.extraProperties = extraProperties
	c.rawJSON = json.RawMessage(data)
	return nil
}

func (c *ClassifyResponseClassificationsItemLabelsValue) String() string {
	if len(c.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(c.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(c); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", c)
}

type DetokenizeResponse struct {
	// A string representing the list of tokens.
	Text *string  `json:"text,omitempty" url:"text,omitempty"`
	Meta *ApiMeta `json:"meta,omitempty" url:"meta,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (d *DetokenizeResponse) GetText() *string {
	if d == nil {
		return nil
	}
	return d.Text
}

func (d *DetokenizeResponse) GetMeta() *ApiMeta {
	if d == nil {
		return nil
	}
	return d.Meta
}

func (d *DetokenizeResponse) GetExtraProperties() map[string]interface{} {
	return d.extraProperties
}

func (d *DetokenizeResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler DetokenizeResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*d = DetokenizeResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *d)
	if err != nil {
		return err
	}
	d.extraProperties = extraProperties
	d.rawJSON = json.RawMessage(data)
	return nil
}

func (d *DetokenizeResponse) String() string {
	if len(d.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(d.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(d); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", d)
}

type EmbedByTypeResponse struct {
	Id string `json:"id" url:"id"`
	// An object with different embedding types. The length of each embedding type array will be the same as the length of the original `texts` array.
	Embeddings *EmbedByTypeResponseEmbeddings `json:"embeddings,omitempty" url:"embeddings,omitempty"`
	// The text entries for which embeddings were returned.
	Texts []string `json:"texts" url:"texts"`
	// The image entries for which embeddings were returned.
	Images []*Image `json:"images,omitempty" url:"images,omitempty"`
	Meta   *ApiMeta `json:"meta,omitempty" url:"meta,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (e *EmbedByTypeResponse) GetId() string {
	if e == nil {
		return ""
	}
	return e.Id
}

func (e *EmbedByTypeResponse) GetEmbeddings() *EmbedByTypeResponseEmbeddings {
	if e == nil {
		return nil
	}
	return e.Embeddings
}

func (e *EmbedByTypeResponse) GetTexts() []string {
	if e == nil {
		return nil
	}
	return e.Texts
}

func (e *EmbedByTypeResponse) GetImages() []*Image {
	if e == nil {
		return nil
	}
	return e.Images
}

func (e *EmbedByTypeResponse) GetMeta() *ApiMeta {
	if e == nil {
		return nil
	}
	return e.Meta
}

func (e *EmbedByTypeResponse) GetExtraProperties() map[string]interface{} {
	return e.extraProperties
}

func (e *EmbedByTypeResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler EmbedByTypeResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*e = EmbedByTypeResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *e)
	if err != nil {
		return err
	}
	e.extraProperties = extraProperties
	e.rawJSON = json.RawMessage(data)
	return nil
}

func (e *EmbedByTypeResponse) String() string {
	if len(e.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(e.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(e); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", e)
}

// An object with different embedding types. The length of each embedding type array will be the same as the length of the original `texts` array.
type EmbedByTypeResponseEmbeddings struct {
	// An array of float embeddings.
	Float [][]float64 `json:"float,omitempty" url:"float,omitempty"`
	// An array of signed int8 embeddings. Each value is between -128 and 127.
	Int8 [][]int `json:"int8,omitempty" url:"int8,omitempty"`
	// An array of unsigned int8 embeddings. Each value is between 0 and 255.
	Uint8 [][]int `json:"uint8,omitempty" url:"uint8,omitempty"`
	// An array of packed signed binary embeddings. The length of each binary embedding is 1/8 the length of the float embeddings of the provided model. Each value is between -128 and 127.
	Binary [][]int `json:"binary,omitempty" url:"binary,omitempty"`
	// An array of packed unsigned binary embeddings. The length of each binary embedding is 1/8 the length of the float embeddings of the provided model. Each value is between 0 and 255.
	Ubinary [][]int `json:"ubinary,omitempty" url:"ubinary,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (e *EmbedByTypeResponseEmbeddings) GetFloat() [][]float64 {
	if e == nil {
		return nil
	}
	return e.Float
}

func (e *EmbedByTypeResponseEmbeddings) GetInt8() [][]int {
	if e == nil {
		return nil
	}
	return e.Int8
}

func (e *EmbedByTypeResponseEmbeddings) GetUint8() [][]int {
	if e == nil {
		return nil
	}
	return e.Uint8
}

func (e *EmbedByTypeResponseEmbeddings) GetBinary() [][]int {
	if e == nil {
		return nil
	}
	return e.Binary
}

func (e *EmbedByTypeResponseEmbeddings) GetUbinary() [][]int {
	if e == nil {
		return nil
	}
	return e.Ubinary
}

func (e *EmbedByTypeResponseEmbeddings) GetExtraProperties() map[string]interface{} {
	return e.extraProperties
}

func (e *EmbedByTypeResponseEmbeddings) UnmarshalJSON(data []byte) error {
	type unmarshaler EmbedByTypeResponseEmbeddings
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*e = EmbedByTypeResponseEmbeddings(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *e)
	if err != nil {
		return err
	}
	e.extraProperties = extraProperties
	e.rawJSON = json.RawMessage(data)
	return nil
}

func (e *EmbedByTypeResponseEmbeddings) String() string {
	if len(e.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(e.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(e); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", e)
}

type EmbedFloatsResponse struct {
	Id string `json:"id" url:"id"`
	// An array of embeddings, where each embedding is an array of floats. The length of the `embeddings` array will be the same as the length of the original `texts` array.
	Embeddings [][]float64 `json:"embeddings,omitempty" url:"embeddings,omitempty"`
	// The text entries for which embeddings were returned.
	Texts []string `json:"texts" url:"texts"`
	// The image entries for which embeddings were returned.
	Images []*Image `json:"images,omitempty" url:"images,omitempty"`
	Meta   *ApiMeta `json:"meta,omitempty" url:"meta,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (e *EmbedFloatsResponse) GetId() string {
	if e == nil {
		return ""
	}
	return e.Id
}

func (e *EmbedFloatsResponse) GetEmbeddings() [][]float64 {
	if e == nil {
		return nil
	}
	return e.Embeddings
}

func (e *EmbedFloatsResponse) GetTexts() []string {
	if e == nil {
		return nil
	}
	return e.Texts
}

func (e *EmbedFloatsResponse) GetImages() []*Image {
	if e == nil {
		return nil
	}
	return e.Images
}

func (e *EmbedFloatsResponse) GetMeta() *ApiMeta {
	if e == nil {
		return nil
	}
	return e.Meta
}

func (e *EmbedFloatsResponse) GetExtraProperties() map[string]interface{} {
	return e.extraProperties
}

func (e *EmbedFloatsResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler EmbedFloatsResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*e = EmbedFloatsResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *e)
	if err != nil {
		return err
	}
	e.extraProperties = extraProperties
	e.rawJSON = json.RawMessage(data)
	return nil
}

func (e *EmbedFloatsResponse) String() string {
	if len(e.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(e.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(e); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", e)
}

// Specifies the type of input passed to the model. Required for embedding models v3 and higher.
//
// - `"search_document"`: Used for embeddings stored in a vector database for search use-cases.
// - `"search_query"`: Used for embeddings of search queries run against a vector DB to find relevant documents.
// - `"classification"`: Used for embeddings passed through a text classifier.
// - `"clustering"`: Used for the embeddings run through a clustering algorithm.
// - `"image"`: Used for embeddings with image input.
type EmbedInputType string

const (
	EmbedInputTypeSearchDocument EmbedInputType = "search_document"
	EmbedInputTypeSearchQuery    EmbedInputType = "search_query"
	EmbedInputTypeClassification EmbedInputType = "classification"
	EmbedInputTypeClustering     EmbedInputType = "clustering"
	EmbedInputTypeImage          EmbedInputType = "image"
)

func NewEmbedInputTypeFromString(s string) (EmbedInputType, error) {
	switch s {
	case "search_document":
		return EmbedInputTypeSearchDocument, nil
	case "search_query":
		return EmbedInputTypeSearchQuery, nil
	case "classification":
		return EmbedInputTypeClassification, nil
	case "clustering":
		return EmbedInputTypeClustering, nil
	case "image":
		return EmbedInputTypeImage, nil
	}
	var t EmbedInputType
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (e EmbedInputType) Ptr() *EmbedInputType {
	return &e
}

// One of `NONE|START|END` to specify how the API will handle inputs longer than the maximum token length.
//
// Passing `START` will discard the start of the input. `END` will discard the end of the input. In both cases, input is discarded until the remaining input is exactly the maximum input token length for the model.
//
// If `NONE` is selected, when the input exceeds the maximum input token length an error will be returned.
type EmbedRequestTruncate string

const (
	EmbedRequestTruncateNone  EmbedRequestTruncate = "NONE"
	EmbedRequestTruncateStart EmbedRequestTruncate = "START"
	EmbedRequestTruncateEnd   EmbedRequestTruncate = "END"
)

func NewEmbedRequestTruncateFromString(s string) (EmbedRequestTruncate, error) {
	switch s {
	case "NONE":
		return EmbedRequestTruncateNone, nil
	case "START":
		return EmbedRequestTruncateStart, nil
	case "END":
		return EmbedRequestTruncateEnd, nil
	}
	var t EmbedRequestTruncate
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (e EmbedRequestTruncate) Ptr() *EmbedRequestTruncate {
	return &e
}

type EmbedResponse struct {
	ResponseType     string
	EmbeddingsFloats *EmbedFloatsResponse
	EmbeddingsByType *EmbedByTypeResponse
}

func (e *EmbedResponse) GetResponseType() string {
	if e == nil {
		return ""
	}
	return e.ResponseType
}

func (e *EmbedResponse) GetEmbeddingsFloats() *EmbedFloatsResponse {
	if e == nil {
		return nil
	}
	return e.EmbeddingsFloats
}

func (e *EmbedResponse) GetEmbeddingsByType() *EmbedByTypeResponse {
	if e == nil {
		return nil
	}
	return e.EmbeddingsByType
}

func (e *EmbedResponse) UnmarshalJSON(data []byte) error {
	var unmarshaler struct {
		ResponseType string `json:"response_type"`
	}
	if err := json.Unmarshal(data, &unmarshaler); err != nil {
		return err
	}
	e.ResponseType = unmarshaler.ResponseType
	if unmarshaler.ResponseType == "" {
		return fmt.Errorf("%T did not include discriminant response_type", e)
	}
	switch unmarshaler.ResponseType {
	case "embeddings_floats":
		value := new(EmbedFloatsResponse)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		e.EmbeddingsFloats = value
	case "embeddings_by_type":
		value := new(EmbedByTypeResponse)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		e.EmbeddingsByType = value
	}
	return nil
}

func (e EmbedResponse) MarshalJSON() ([]byte, error) {
	if err := e.validate(); err != nil {
		return nil, err
	}
	if e.EmbeddingsFloats != nil {
		return internal.MarshalJSONWithExtraProperty(e.EmbeddingsFloats, "response_type", "embeddings_floats")
	}
	if e.EmbeddingsByType != nil {
		return internal.MarshalJSONWithExtraProperty(e.EmbeddingsByType, "response_type", "embeddings_by_type")
	}
	return nil, fmt.Errorf("type %T does not define a non-empty union type", e)
}

type EmbedResponseVisitor interface {
	VisitEmbeddingsFloats(*EmbedFloatsResponse) error
	VisitEmbeddingsByType(*EmbedByTypeResponse) error
}

func (e *EmbedResponse) Accept(visitor EmbedResponseVisitor) error {
	if e.EmbeddingsFloats != nil {
		return visitor.VisitEmbeddingsFloats(e.EmbeddingsFloats)
	}
	if e.EmbeddingsByType != nil {
		return visitor.VisitEmbeddingsByType(e.EmbeddingsByType)
	}
	return fmt.Errorf("type %T does not define a non-empty union type", e)
}

func (e *EmbedResponse) validate() error {
	if e == nil {
		return fmt.Errorf("type %T is nil", e)
	}
	var fields []string
	if e.EmbeddingsFloats != nil {
		fields = append(fields, "embeddings_floats")
	}
	if e.EmbeddingsByType != nil {
		fields = append(fields, "embeddings_by_type")
	}
	if len(fields) == 0 {
		if e.ResponseType != "" {
			return fmt.Errorf("type %T defines a discriminant set to %q but the field is not set", e, e.ResponseType)
		}
		return fmt.Errorf("type %T is empty", e)
	}
	if len(fields) > 1 {
		return fmt.Errorf("type %T defines values for %s, but only one value is allowed", e, fields)
	}
	if e.ResponseType != "" {
		field := fields[0]
		if e.ResponseType != field {
			return fmt.Errorf(
				"type %T defines a discriminant set to %q, but it does not match the %T field; either remove or update the discriminant to match",
				e,
				e.ResponseType,
				e,
			)
		}
	}
	return nil
}

type EmbeddingType string

const (
	EmbeddingTypeFloat   EmbeddingType = "float"
	EmbeddingTypeInt8    EmbeddingType = "int8"
	EmbeddingTypeUint8   EmbeddingType = "uint8"
	EmbeddingTypeBinary  EmbeddingType = "binary"
	EmbeddingTypeUbinary EmbeddingType = "ubinary"
)

func NewEmbeddingTypeFromString(s string) (EmbeddingType, error) {
	switch s {
	case "float":
		return EmbeddingTypeFloat, nil
	case "int8":
		return EmbeddingTypeInt8, nil
	case "uint8":
		return EmbeddingTypeUint8, nil
	case "binary":
		return EmbeddingTypeBinary, nil
	case "ubinary":
		return EmbeddingTypeUbinary, nil
	}
	var t EmbeddingType
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (e EmbeddingType) Ptr() *EmbeddingType {
	return &e
}

type FinishReason string

const (
	FinishReasonComplete     FinishReason = "COMPLETE"
	FinishReasonStopSequence FinishReason = "STOP_SEQUENCE"
	FinishReasonError        FinishReason = "ERROR"
	FinishReasonErrorToxic   FinishReason = "ERROR_TOXIC"
	FinishReasonErrorLimit   FinishReason = "ERROR_LIMIT"
	FinishReasonUserCancel   FinishReason = "USER_CANCEL"
	FinishReasonMaxTokens    FinishReason = "MAX_TOKENS"
)

func NewFinishReasonFromString(s string) (FinishReason, error) {
	switch s {
	case "COMPLETE":
		return FinishReasonComplete, nil
	case "STOP_SEQUENCE":
		return FinishReasonStopSequence, nil
	case "ERROR":
		return FinishReasonError, nil
	case "ERROR_TOXIC":
		return FinishReasonErrorToxic, nil
	case "ERROR_LIMIT":
		return FinishReasonErrorLimit, nil
	case "USER_CANCEL":
		return FinishReasonUserCancel, nil
	case "MAX_TOKENS":
		return FinishReasonMaxTokens, nil
	}
	var t FinishReason
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (f FinishReason) Ptr() *FinishReason {
	return &f
}

// One of `GENERATION|NONE` to specify how and if the token likelihoods are returned with the response. Defaults to `NONE`.
//
// If `GENERATION` is selected, the token likelihoods will only be provided for generated text.
//
// WARNING: `ALL` is deprecated, and will be removed in a future release.
type GenerateRequestReturnLikelihoods string

const (
	GenerateRequestReturnLikelihoodsGeneration GenerateRequestReturnLikelihoods = "GENERATION"
	GenerateRequestReturnLikelihoodsAll        GenerateRequestReturnLikelihoods = "ALL"
	GenerateRequestReturnLikelihoodsNone       GenerateRequestReturnLikelihoods = "NONE"
)

func NewGenerateRequestReturnLikelihoodsFromString(s string) (GenerateRequestReturnLikelihoods, error) {
	switch s {
	case "GENERATION":
		return GenerateRequestReturnLikelihoodsGeneration, nil
	case "ALL":
		return GenerateRequestReturnLikelihoodsAll, nil
	case "NONE":
		return GenerateRequestReturnLikelihoodsNone, nil
	}
	var t GenerateRequestReturnLikelihoods
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (g GenerateRequestReturnLikelihoods) Ptr() *GenerateRequestReturnLikelihoods {
	return &g
}

// One of `NONE|START|END` to specify how the API will handle inputs longer than the maximum token length.
//
// Passing `START` will discard the start of the input. `END` will discard the end of the input. In both cases, input is discarded until the remaining input is exactly the maximum input token length for the model.
//
// If `NONE` is selected, when the input exceeds the maximum input token length an error will be returned.
type GenerateRequestTruncate string

const (
	GenerateRequestTruncateNone  GenerateRequestTruncate = "NONE"
	GenerateRequestTruncateStart GenerateRequestTruncate = "START"
	GenerateRequestTruncateEnd   GenerateRequestTruncate = "END"
)

func NewGenerateRequestTruncateFromString(s string) (GenerateRequestTruncate, error) {
	switch s {
	case "NONE":
		return GenerateRequestTruncateNone, nil
	case "START":
		return GenerateRequestTruncateStart, nil
	case "END":
		return GenerateRequestTruncateEnd, nil
	}
	var t GenerateRequestTruncate
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (g GenerateRequestTruncate) Ptr() *GenerateRequestTruncate {
	return &g
}

type GenerateStreamEnd struct {
	IsFinished   bool                       `json:"is_finished" url:"is_finished"`
	FinishReason *FinishReason              `json:"finish_reason,omitempty" url:"finish_reason,omitempty"`
	Response     *GenerateStreamEndResponse `json:"response" url:"response"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (g *GenerateStreamEnd) GetIsFinished() bool {
	if g == nil {
		return false
	}
	return g.IsFinished
}

func (g *GenerateStreamEnd) GetFinishReason() *FinishReason {
	if g == nil {
		return nil
	}
	return g.FinishReason
}

func (g *GenerateStreamEnd) GetResponse() *GenerateStreamEndResponse {
	if g == nil {
		return nil
	}
	return g.Response
}

func (g *GenerateStreamEnd) GetExtraProperties() map[string]interface{} {
	return g.extraProperties
}

func (g *GenerateStreamEnd) UnmarshalJSON(data []byte) error {
	type unmarshaler GenerateStreamEnd
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*g = GenerateStreamEnd(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *g)
	if err != nil {
		return err
	}
	g.extraProperties = extraProperties
	g.rawJSON = json.RawMessage(data)
	return nil
}

func (g *GenerateStreamEnd) String() string {
	if len(g.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(g.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(g); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", g)
}

type GenerateStreamEndResponse struct {
	Id          string                      `json:"id" url:"id"`
	Prompt      *string                     `json:"prompt,omitempty" url:"prompt,omitempty"`
	Generations []*SingleGenerationInStream `json:"generations,omitempty" url:"generations,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (g *GenerateStreamEndResponse) GetId() string {
	if g == nil {
		return ""
	}
	return g.Id
}

func (g *GenerateStreamEndResponse) GetPrompt() *string {
	if g == nil {
		return nil
	}
	return g.Prompt
}

func (g *GenerateStreamEndResponse) GetGenerations() []*SingleGenerationInStream {
	if g == nil {
		return nil
	}
	return g.Generations
}

func (g *GenerateStreamEndResponse) GetExtraProperties() map[string]interface{} {
	return g.extraProperties
}

func (g *GenerateStreamEndResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler GenerateStreamEndResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*g = GenerateStreamEndResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *g)
	if err != nil {
		return err
	}
	g.extraProperties = extraProperties
	g.rawJSON = json.RawMessage(data)
	return nil
}

func (g *GenerateStreamEndResponse) String() string {
	if len(g.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(g.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(g); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", g)
}

type GenerateStreamError struct {
	// Refers to the nth generation. Only present when `num_generations` is greater than zero.
	Index        *int         `json:"index,omitempty" url:"index,omitempty"`
	IsFinished   bool         `json:"is_finished" url:"is_finished"`
	FinishReason FinishReason `json:"finish_reason" url:"finish_reason"`
	// Error message
	Err string `json:"err" url:"err"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (g *GenerateStreamError) GetIndex() *int {
	if g == nil {
		return nil
	}
	return g.Index
}

func (g *GenerateStreamError) GetIsFinished() bool {
	if g == nil {
		return false
	}
	return g.IsFinished
}

func (g *GenerateStreamError) GetFinishReason() FinishReason {
	if g == nil {
		return ""
	}
	return g.FinishReason
}

func (g *GenerateStreamError) GetErr() string {
	if g == nil {
		return ""
	}
	return g.Err
}

func (g *GenerateStreamError) GetExtraProperties() map[string]interface{} {
	return g.extraProperties
}

func (g *GenerateStreamError) UnmarshalJSON(data []byte) error {
	type unmarshaler GenerateStreamError
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*g = GenerateStreamError(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *g)
	if err != nil {
		return err
	}
	g.extraProperties = extraProperties
	g.rawJSON = json.RawMessage(data)
	return nil
}

func (g *GenerateStreamError) String() string {
	if len(g.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(g.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(g); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", g)
}

type GenerateStreamEvent struct {
	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (g *GenerateStreamEvent) GetExtraProperties() map[string]interface{} {
	return g.extraProperties
}

func (g *GenerateStreamEvent) UnmarshalJSON(data []byte) error {
	type unmarshaler GenerateStreamEvent
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*g = GenerateStreamEvent(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *g)
	if err != nil {
		return err
	}
	g.extraProperties = extraProperties
	g.rawJSON = json.RawMessage(data)
	return nil
}

func (g *GenerateStreamEvent) String() string {
	if len(g.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(g.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(g); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", g)
}

// One of `GENERATION|NONE` to specify how and if the token likelihoods are returned with the response. Defaults to `NONE`.
//
// If `GENERATION` is selected, the token likelihoods will only be provided for generated text.
//
// WARNING: `ALL` is deprecated, and will be removed in a future release.
type GenerateStreamRequestReturnLikelihoods string

const (
	GenerateStreamRequestReturnLikelihoodsGeneration GenerateStreamRequestReturnLikelihoods = "GENERATION"
	GenerateStreamRequestReturnLikelihoodsAll        GenerateStreamRequestReturnLikelihoods = "ALL"
	GenerateStreamRequestReturnLikelihoodsNone       GenerateStreamRequestReturnLikelihoods = "NONE"
)

func NewGenerateStreamRequestReturnLikelihoodsFromString(s string) (GenerateStreamRequestReturnLikelihoods, error) {
	switch s {
	case "GENERATION":
		return GenerateStreamRequestReturnLikelihoodsGeneration, nil
	case "ALL":
		return GenerateStreamRequestReturnLikelihoodsAll, nil
	case "NONE":
		return GenerateStreamRequestReturnLikelihoodsNone, nil
	}
	var t GenerateStreamRequestReturnLikelihoods
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (g GenerateStreamRequestReturnLikelihoods) Ptr() *GenerateStreamRequestReturnLikelihoods {
	return &g
}

// One of `NONE|START|END` to specify how the API will handle inputs longer than the maximum token length.
//
// Passing `START` will discard the start of the input. `END` will discard the end of the input. In both cases, input is discarded until the remaining input is exactly the maximum input token length for the model.
//
// If `NONE` is selected, when the input exceeds the maximum input token length an error will be returned.
type GenerateStreamRequestTruncate string

const (
	GenerateStreamRequestTruncateNone  GenerateStreamRequestTruncate = "NONE"
	GenerateStreamRequestTruncateStart GenerateStreamRequestTruncate = "START"
	GenerateStreamRequestTruncateEnd   GenerateStreamRequestTruncate = "END"
)

func NewGenerateStreamRequestTruncateFromString(s string) (GenerateStreamRequestTruncate, error) {
	switch s {
	case "NONE":
		return GenerateStreamRequestTruncateNone, nil
	case "START":
		return GenerateStreamRequestTruncateStart, nil
	case "END":
		return GenerateStreamRequestTruncateEnd, nil
	}
	var t GenerateStreamRequestTruncate
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (g GenerateStreamRequestTruncate) Ptr() *GenerateStreamRequestTruncate {
	return &g
}

type GenerateStreamText struct {
	// A segment of text of the generation.
	Text string `json:"text" url:"text"`
	// Refers to the nth generation. Only present when `num_generations` is greater than zero, and only when text responses are being streamed.
	Index      *int `json:"index,omitempty" url:"index,omitempty"`
	IsFinished bool `json:"is_finished" url:"is_finished"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (g *GenerateStreamText) GetText() string {
	if g == nil {
		return ""
	}
	return g.Text
}

func (g *GenerateStreamText) GetIndex() *int {
	if g == nil {
		return nil
	}
	return g.Index
}

func (g *GenerateStreamText) GetIsFinished() bool {
	if g == nil {
		return false
	}
	return g.IsFinished
}

func (g *GenerateStreamText) GetExtraProperties() map[string]interface{} {
	return g.extraProperties
}

func (g *GenerateStreamText) UnmarshalJSON(data []byte) error {
	type unmarshaler GenerateStreamText
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*g = GenerateStreamText(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *g)
	if err != nil {
		return err
	}
	g.extraProperties = extraProperties
	g.rawJSON = json.RawMessage(data)
	return nil
}

func (g *GenerateStreamText) String() string {
	if len(g.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(g.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(g); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", g)
}

// Response in content type stream when `stream` is `true` in the request parameters. Generation tokens are streamed with the GenerationStream response. The final response is of type GenerationFinalResponse.
type GenerateStreamedResponse struct {
	EventType      string
	TextGeneration *GenerateStreamText
	StreamEnd      *GenerateStreamEnd
	StreamError    *GenerateStreamError
}

func (g *GenerateStreamedResponse) GetEventType() string {
	if g == nil {
		return ""
	}
	return g.EventType
}

func (g *GenerateStreamedResponse) GetTextGeneration() *GenerateStreamText {
	if g == nil {
		return nil
	}
	return g.TextGeneration
}

func (g *GenerateStreamedResponse) GetStreamEnd() *GenerateStreamEnd {
	if g == nil {
		return nil
	}
	return g.StreamEnd
}

func (g *GenerateStreamedResponse) GetStreamError() *GenerateStreamError {
	if g == nil {
		return nil
	}
	return g.StreamError
}

func (g *GenerateStreamedResponse) UnmarshalJSON(data []byte) error {
	var unmarshaler struct {
		EventType string `json:"event_type"`
	}
	if err := json.Unmarshal(data, &unmarshaler); err != nil {
		return err
	}
	g.EventType = unmarshaler.EventType
	if unmarshaler.EventType == "" {
		return fmt.Errorf("%T did not include discriminant event_type", g)
	}
	switch unmarshaler.EventType {
	case "text-generation":
		value := new(GenerateStreamText)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		g.TextGeneration = value
	case "stream-end":
		value := new(GenerateStreamEnd)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		g.StreamEnd = value
	case "stream-error":
		value := new(GenerateStreamError)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		g.StreamError = value
	}
	return nil
}

func (g GenerateStreamedResponse) MarshalJSON() ([]byte, error) {
	if err := g.validate(); err != nil {
		return nil, err
	}
	if g.TextGeneration != nil {
		return internal.MarshalJSONWithExtraProperty(g.TextGeneration, "event_type", "text-generation")
	}
	if g.StreamEnd != nil {
		return internal.MarshalJSONWithExtraProperty(g.StreamEnd, "event_type", "stream-end")
	}
	if g.StreamError != nil {
		return internal.MarshalJSONWithExtraProperty(g.StreamError, "event_type", "stream-error")
	}
	return nil, fmt.Errorf("type %T does not define a non-empty union type", g)
}

type GenerateStreamedResponseVisitor interface {
	VisitTextGeneration(*GenerateStreamText) error
	VisitStreamEnd(*GenerateStreamEnd) error
	VisitStreamError(*GenerateStreamError) error
}

func (g *GenerateStreamedResponse) Accept(visitor GenerateStreamedResponseVisitor) error {
	if g.TextGeneration != nil {
		return visitor.VisitTextGeneration(g.TextGeneration)
	}
	if g.StreamEnd != nil {
		return visitor.VisitStreamEnd(g.StreamEnd)
	}
	if g.StreamError != nil {
		return visitor.VisitStreamError(g.StreamError)
	}
	return fmt.Errorf("type %T does not define a non-empty union type", g)
}

func (g *GenerateStreamedResponse) validate() error {
	if g == nil {
		return fmt.Errorf("type %T is nil", g)
	}
	var fields []string
	if g.TextGeneration != nil {
		fields = append(fields, "text-generation")
	}
	if g.StreamEnd != nil {
		fields = append(fields, "stream-end")
	}
	if g.StreamError != nil {
		fields = append(fields, "stream-error")
	}
	if len(fields) == 0 {
		if g.EventType != "" {
			return fmt.Errorf("type %T defines a discriminant set to %q but the field is not set", g, g.EventType)
		}
		return fmt.Errorf("type %T is empty", g)
	}
	if len(fields) > 1 {
		return fmt.Errorf("type %T defines values for %s, but only one value is allowed", g, fields)
	}
	if g.EventType != "" {
		field := fields[0]
		if g.EventType != field {
			return fmt.Errorf(
				"type %T defines a discriminant set to %q, but it does not match the %T field; either remove or update the discriminant to match",
				g,
				g.EventType,
				g,
			)
		}
	}
	return nil
}

type Generation struct {
	Id string `json:"id" url:"id"`
	// Prompt used for generations.
	Prompt *string `json:"prompt,omitempty" url:"prompt,omitempty"`
	// List of generated results
	Generations []*SingleGeneration `json:"generations" url:"generations"`
	Meta        *ApiMeta            `json:"meta,omitempty" url:"meta,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (g *Generation) GetId() string {
	if g == nil {
		return ""
	}
	return g.Id
}

func (g *Generation) GetPrompt() *string {
	if g == nil {
		return nil
	}
	return g.Prompt
}

func (g *Generation) GetGenerations() []*SingleGeneration {
	if g == nil {
		return nil
	}
	return g.Generations
}

func (g *Generation) GetMeta() *ApiMeta {
	if g == nil {
		return nil
	}
	return g.Meta
}

func (g *Generation) GetExtraProperties() map[string]interface{} {
	return g.extraProperties
}

func (g *Generation) UnmarshalJSON(data []byte) error {
	type unmarshaler Generation
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*g = Generation(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *g)
	if err != nil {
		return err
	}
	g.extraProperties = extraProperties
	g.rawJSON = json.RawMessage(data)
	return nil
}

func (g *Generation) String() string {
	if len(g.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(g.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(g); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", g)
}

type Image struct {
	// Width of the image in pixels
	Width int64 `json:"width" url:"width"`
	// Height of the image in pixels
	Height int64 `json:"height" url:"height"`
	// Format of the image
	Format string `json:"format" url:"format"`
	// Bit depth of the image
	BitDepth int64 `json:"bit_depth" url:"bit_depth"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (i *Image) GetWidth() int64 {
	if i == nil {
		return 0
	}
	return i.Width
}

func (i *Image) GetHeight() int64 {
	if i == nil {
		return 0
	}
	return i.Height
}

func (i *Image) GetFormat() string {
	if i == nil {
		return ""
	}
	return i.Format
}

func (i *Image) GetBitDepth() int64 {
	if i == nil {
		return 0
	}
	return i.BitDepth
}

func (i *Image) GetExtraProperties() map[string]interface{} {
	return i.extraProperties
}

func (i *Image) UnmarshalJSON(data []byte) error {
	type unmarshaler Image
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*i = Image(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *i)
	if err != nil {
		return err
	}
	i.extraProperties = extraProperties
	i.rawJSON = json.RawMessage(data)
	return nil
}

func (i *Image) String() string {
	if len(i.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(i.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(i); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", i)
}

type JsonResponseFormat struct {
	// A JSON schema object that the output will adhere to. There are some restrictions we have on the schema, refer to [our guide](https://docs.cohere.com/docs/structured-outputs-json#schema-constraints) for more information.
	// Example (required name and age object):
	// ```json
	//
	//	{
	//	  "type": "object",
	//	  "properties": {
	//	    "name": {"type": "string"},
	//	    "age": {"type": "integer"}
	//	  },
	//	  "required": ["name", "age"]
	//	}
	//
	// ```
	//
	// **Note**: This field must not be specified when the `type` is set to `"text"`.
	Schema map[string]interface{} `json:"schema,omitempty" url:"schema,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (j *JsonResponseFormat) GetSchema() map[string]interface{} {
	if j == nil {
		return nil
	}
	return j.Schema
}

func (j *JsonResponseFormat) GetExtraProperties() map[string]interface{} {
	return j.extraProperties
}

func (j *JsonResponseFormat) UnmarshalJSON(data []byte) error {
	type unmarshaler JsonResponseFormat
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*j = JsonResponseFormat(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *j)
	if err != nil {
		return err
	}
	j.extraProperties = extraProperties
	j.rawJSON = json.RawMessage(data)
	return nil
}

func (j *JsonResponseFormat) String() string {
	if len(j.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(j.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(j); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", j)
}

type Message struct {
	Role    string
	Chatbot *ChatMessage
	System  *ChatMessage
	User    *ChatMessage
	Tool    *ChatToolMessage
}

func (m *Message) GetRole() string {
	if m == nil {
		return ""
	}
	return m.Role
}

func (m *Message) GetChatbot() *ChatMessage {
	if m == nil {
		return nil
	}
	return m.Chatbot
}

func (m *Message) GetSystem() *ChatMessage {
	if m == nil {
		return nil
	}
	return m.System
}

func (m *Message) GetUser() *ChatMessage {
	if m == nil {
		return nil
	}
	return m.User
}

func (m *Message) GetTool() *ChatToolMessage {
	if m == nil {
		return nil
	}
	return m.Tool
}

func (m *Message) UnmarshalJSON(data []byte) error {
	var unmarshaler struct {
		Role string `json:"role"`
	}
	if err := json.Unmarshal(data, &unmarshaler); err != nil {
		return err
	}
	m.Role = unmarshaler.Role
	if unmarshaler.Role == "" {
		return fmt.Errorf("%T did not include discriminant role", m)
	}
	switch unmarshaler.Role {
	case "CHATBOT":
		value := new(ChatMessage)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		m.Chatbot = value
	case "SYSTEM":
		value := new(ChatMessage)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		m.System = value
	case "USER":
		value := new(ChatMessage)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		m.User = value
	case "TOOL":
		value := new(ChatToolMessage)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		m.Tool = value
	}
	return nil
}

func (m Message) MarshalJSON() ([]byte, error) {
	if err := m.validate(); err != nil {
		return nil, err
	}
	if m.Chatbot != nil {
		return internal.MarshalJSONWithExtraProperty(m.Chatbot, "role", "CHATBOT")
	}
	if m.System != nil {
		return internal.MarshalJSONWithExtraProperty(m.System, "role", "SYSTEM")
	}
	if m.User != nil {
		return internal.MarshalJSONWithExtraProperty(m.User, "role", "USER")
	}
	if m.Tool != nil {
		return internal.MarshalJSONWithExtraProperty(m.Tool, "role", "TOOL")
	}
	return nil, fmt.Errorf("type %T does not define a non-empty union type", m)
}

type MessageVisitor interface {
	VisitChatbot(*ChatMessage) error
	VisitSystem(*ChatMessage) error
	VisitUser(*ChatMessage) error
	VisitTool(*ChatToolMessage) error
}

func (m *Message) Accept(visitor MessageVisitor) error {
	if m.Chatbot != nil {
		return visitor.VisitChatbot(m.Chatbot)
	}
	if m.System != nil {
		return visitor.VisitSystem(m.System)
	}
	if m.User != nil {
		return visitor.VisitUser(m.User)
	}
	if m.Tool != nil {
		return visitor.VisitTool(m.Tool)
	}
	return fmt.Errorf("type %T does not define a non-empty union type", m)
}

func (m *Message) validate() error {
	if m == nil {
		return fmt.Errorf("type %T is nil", m)
	}
	var fields []string
	if m.Chatbot != nil {
		fields = append(fields, "CHATBOT")
	}
	if m.System != nil {
		fields = append(fields, "SYSTEM")
	}
	if m.User != nil {
		fields = append(fields, "USER")
	}
	if m.Tool != nil {
		fields = append(fields, "TOOL")
	}
	if len(fields) == 0 {
		if m.Role != "" {
			return fmt.Errorf("type %T defines a discriminant set to %q but the field is not set", m, m.Role)
		}
		return fmt.Errorf("type %T is empty", m)
	}
	if len(fields) > 1 {
		return fmt.Errorf("type %T defines values for %s, but only one value is allowed", m, fields)
	}
	if m.Role != "" {
		field := fields[0]
		if m.Role != field {
			return fmt.Errorf(
				"type %T defines a discriminant set to %q, but it does not match the %T field; either remove or update the discriminant to match",
				m,
				m.Role,
				m,
			)
		}
	}
	return nil
}

type NonStreamedChatResponse struct {
	// Contents of the reply generated by the model.
	Text string `json:"text" url:"text"`
	// Unique identifier for the generated reply. Useful for submitting feedback.
	GenerationId *string `json:"generation_id,omitempty" url:"generation_id,omitempty"`
	// Unique identifier for the response.
	ResponseId *string `json:"response_id,omitempty" url:"response_id,omitempty"`
	// Inline citations for the generated reply.
	Citations []*ChatCitation `json:"citations,omitempty" url:"citations,omitempty"`
	// Documents seen by the model when generating the reply.
	Documents []ChatDocument `json:"documents,omitempty" url:"documents,omitempty"`
	// Denotes that a search for documents is required during the RAG flow.
	IsSearchRequired *bool `json:"is_search_required,omitempty" url:"is_search_required,omitempty"`
	// Generated search queries, meant to be used as part of the RAG flow.
	SearchQueries []*ChatSearchQuery `json:"search_queries,omitempty" url:"search_queries,omitempty"`
	// Documents retrieved from each of the conducted searches.
	SearchResults []*ChatSearchResult `json:"search_results,omitempty" url:"search_results,omitempty"`
	FinishReason  *FinishReason       `json:"finish_reason,omitempty" url:"finish_reason,omitempty"`
	ToolCalls     []*ToolCall         `json:"tool_calls,omitempty" url:"tool_calls,omitempty"`
	// A list of previous messages between the user and the model, meant to give the model conversational context for responding to the user's `message`.
	ChatHistory []*Message `json:"chat_history,omitempty" url:"chat_history,omitempty"`
	Meta        *ApiMeta   `json:"meta,omitempty" url:"meta,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (n *NonStreamedChatResponse) GetText() string {
	if n == nil {
		return ""
	}
	return n.Text
}

func (n *NonStreamedChatResponse) GetGenerationId() *string {
	if n == nil {
		return nil
	}
	return n.GenerationId
}

func (n *NonStreamedChatResponse) GetResponseId() *string {
	if n == nil {
		return nil
	}
	return n.ResponseId
}

func (n *NonStreamedChatResponse) GetCitations() []*ChatCitation {
	if n == nil {
		return nil
	}
	return n.Citations
}

func (n *NonStreamedChatResponse) GetDocuments() []ChatDocument {
	if n == nil {
		return nil
	}
	return n.Documents
}

func (n *NonStreamedChatResponse) GetIsSearchRequired() *bool {
	if n == nil {
		return nil
	}
	return n.IsSearchRequired
}

func (n *NonStreamedChatResponse) GetSearchQueries() []*ChatSearchQuery {
	if n == nil {
		return nil
	}
	return n.SearchQueries
}

func (n *NonStreamedChatResponse) GetSearchResults() []*ChatSearchResult {
	if n == nil {
		return nil
	}
	return n.SearchResults
}

func (n *NonStreamedChatResponse) GetFinishReason() *FinishReason {
	if n == nil {
		return nil
	}
	return n.FinishReason
}

func (n *NonStreamedChatResponse) GetToolCalls() []*ToolCall {
	if n == nil {
		return nil
	}
	return n.ToolCalls
}

func (n *NonStreamedChatResponse) GetChatHistory() []*Message {
	if n == nil {
		return nil
	}
	return n.ChatHistory
}

func (n *NonStreamedChatResponse) GetMeta() *ApiMeta {
	if n == nil {
		return nil
	}
	return n.Meta
}

func (n *NonStreamedChatResponse) GetExtraProperties() map[string]interface{} {
	return n.extraProperties
}

func (n *NonStreamedChatResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler NonStreamedChatResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*n = NonStreamedChatResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *n)
	if err != nil {
		return err
	}
	n.extraProperties = extraProperties
	n.rawJSON = json.RawMessage(data)
	return nil
}

func (n *NonStreamedChatResponse) String() string {
	if len(n.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(n.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(n); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", n)
}

type RerankDocument = map[string]string

type RerankRequestDocumentsItem struct {
	String         string
	RerankDocument RerankDocument

	typ string
}

func (r *RerankRequestDocumentsItem) GetString() string {
	if r == nil {
		return ""
	}
	return r.String
}

func (r *RerankRequestDocumentsItem) GetRerankDocument() RerankDocument {
	if r == nil {
		return nil
	}
	return r.RerankDocument
}

func (r *RerankRequestDocumentsItem) UnmarshalJSON(data []byte) error {
	var valueString string
	if err := json.Unmarshal(data, &valueString); err == nil {
		r.typ = "String"
		r.String = valueString
		return nil
	}
	var valueRerankDocument RerankDocument
	if err := json.Unmarshal(data, &valueRerankDocument); err == nil {
		r.typ = "RerankDocument"
		r.RerankDocument = valueRerankDocument
		return nil
	}
	return fmt.Errorf("%s cannot be deserialized as a %T", data, r)
}

func (r RerankRequestDocumentsItem) MarshalJSON() ([]byte, error) {
	if r.typ == "String" || r.String != "" {
		return json.Marshal(r.String)
	}
	if r.typ == "RerankDocument" || r.RerankDocument != nil {
		return json.Marshal(r.RerankDocument)
	}
	return nil, fmt.Errorf("type %T does not include a non-empty union type", r)
}

type RerankRequestDocumentsItemVisitor interface {
	VisitString(string) error
	VisitRerankDocument(RerankDocument) error
}

func (r *RerankRequestDocumentsItem) Accept(visitor RerankRequestDocumentsItemVisitor) error {
	if r.typ == "String" || r.String != "" {
		return visitor.VisitString(r.String)
	}
	if r.typ == "RerankDocument" || r.RerankDocument != nil {
		return visitor.VisitRerankDocument(r.RerankDocument)
	}
	return fmt.Errorf("type %T does not include a non-empty union type", r)
}

type RerankResponse struct {
	Id *string `json:"id,omitempty" url:"id,omitempty"`
	// An ordered list of ranked documents
	Results []*RerankResponseResultsItem `json:"results" url:"results"`
	Meta    *ApiMeta                     `json:"meta,omitempty" url:"meta,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (r *RerankResponse) GetId() *string {
	if r == nil {
		return nil
	}
	return r.Id
}

func (r *RerankResponse) GetResults() []*RerankResponseResultsItem {
	if r == nil {
		return nil
	}
	return r.Results
}

func (r *RerankResponse) GetMeta() *ApiMeta {
	if r == nil {
		return nil
	}
	return r.Meta
}

func (r *RerankResponse) GetExtraProperties() map[string]interface{} {
	return r.extraProperties
}

func (r *RerankResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler RerankResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*r = RerankResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *r)
	if err != nil {
		return err
	}
	r.extraProperties = extraProperties
	r.rawJSON = json.RawMessage(data)
	return nil
}

func (r *RerankResponse) String() string {
	if len(r.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(r.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(r); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", r)
}

type RerankResponseResultsItem struct {
	// If `return_documents` is set as `false` this will return none, if `true` it will return the documents passed in
	Document *RerankResponseResultsItemDocument `json:"document,omitempty" url:"document,omitempty"`
	// Corresponds to the index in the original list of documents to which the ranked document belongs. (i.e. if the first value in the `results` object has an `index` value of 3, it means in the list of documents passed in, the document at `index=3` had the highest relevance)
	Index int `json:"index" url:"index"`
	// Relevance scores are normalized to be in the range `[0, 1]`. Scores close to `1` indicate a high relevance to the query, and scores closer to `0` indicate low relevance. It is not accurate to assume a score of 0.9 means the document is 2x more relevant than a document with a score of 0.45
	RelevanceScore *float64 `json:"relevance_score,omitempty" url:"relevance_score,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (r *RerankResponseResultsItem) GetDocument() *RerankResponseResultsItemDocument {
	if r == nil {
		return nil
	}
	return r.Document
}

func (r *RerankResponseResultsItem) GetIndex() int {
	if r == nil {
		return 0
	}
	return r.Index
}

func (r *RerankResponseResultsItem) GetRelevanceScore() *float64 {
	if r == nil {
		return nil
	}
	return r.RelevanceScore
}

func (r *RerankResponseResultsItem) GetExtraProperties() map[string]interface{} {
	return r.extraProperties
}

func (r *RerankResponseResultsItem) UnmarshalJSON(data []byte) error {
	type unmarshaler RerankResponseResultsItem
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*r = RerankResponseResultsItem(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *r)
	if err != nil {
		return err
	}
	r.extraProperties = extraProperties
	r.rawJSON = json.RawMessage(data)
	return nil
}

func (r *RerankResponseResultsItem) String() string {
	if len(r.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(r.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(r); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", r)
}

// If `return_documents` is set as `false` this will return none, if `true` it will return the documents passed in
type RerankResponseResultsItemDocument struct {
	// The text of the document to rerank
	Text string `json:"text" url:"text"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (r *RerankResponseResultsItemDocument) GetText() string {
	if r == nil {
		return ""
	}
	return r.Text
}

func (r *RerankResponseResultsItemDocument) GetExtraProperties() map[string]interface{} {
	return r.extraProperties
}

func (r *RerankResponseResultsItemDocument) UnmarshalJSON(data []byte) error {
	type unmarshaler RerankResponseResultsItemDocument
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*r = RerankResponseResultsItemDocument(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *r)
	if err != nil {
		return err
	}
	r.extraProperties = extraProperties
	r.rawJSON = json.RawMessage(data)
	return nil
}

func (r *RerankResponseResultsItemDocument) String() string {
	if len(r.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(r.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(r); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", r)
}

// Configuration for forcing the model output to adhere to the specified format. Supported on [Command R 03-2024](https://docs.cohere.com/docs/command-r), [Command R+ 04-2024](https://docs.cohere.com/docs/command-r-plus) and newer models.
//
// The model can be forced into outputting JSON objects (with up to 5 levels of nesting) by setting `{ "type": "json_object" }`.
//
// A [JSON Schema](https://json-schema.org/) can optionally be provided, to ensure a specific structure.
//
// **Note**: When using  `{ "type": "json_object" }` your `message` should always explicitly instruct the model to generate a JSON (eg: _"Generate a JSON ..."_) . Otherwise the model may end up getting stuck generating an infinite stream of characters and eventually run out of context length.
// **Limitation**: The parameter is not supported in RAG mode (when any of `connectors`, `documents`, `tools`, `tool_results` are provided).
type ResponseFormat struct {
	Type       string
	Text       *ChatTextResponseFormat
	JsonObject *JsonResponseFormat
}

func (r *ResponseFormat) GetType() string {
	if r == nil {
		return ""
	}
	return r.Type
}

func (r *ResponseFormat) GetText() *ChatTextResponseFormat {
	if r == nil {
		return nil
	}
	return r.Text
}

func (r *ResponseFormat) GetJsonObject() *JsonResponseFormat {
	if r == nil {
		return nil
	}
	return r.JsonObject
}

func (r *ResponseFormat) UnmarshalJSON(data []byte) error {
	var unmarshaler struct {
		Type string `json:"type"`
	}
	if err := json.Unmarshal(data, &unmarshaler); err != nil {
		return err
	}
	r.Type = unmarshaler.Type
	if unmarshaler.Type == "" {
		return fmt.Errorf("%T did not include discriminant type", r)
	}
	switch unmarshaler.Type {
	case "text":
		value := new(ChatTextResponseFormat)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		r.Text = value
	case "json_object":
		value := new(JsonResponseFormat)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		r.JsonObject = value
	}
	return nil
}

func (r ResponseFormat) MarshalJSON() ([]byte, error) {
	if err := r.validate(); err != nil {
		return nil, err
	}
	if r.Text != nil {
		return internal.MarshalJSONWithExtraProperty(r.Text, "type", "text")
	}
	if r.JsonObject != nil {
		return internal.MarshalJSONWithExtraProperty(r.JsonObject, "type", "json_object")
	}
	return nil, fmt.Errorf("type %T does not define a non-empty union type", r)
}

type ResponseFormatVisitor interface {
	VisitText(*ChatTextResponseFormat) error
	VisitJsonObject(*JsonResponseFormat) error
}

func (r *ResponseFormat) Accept(visitor ResponseFormatVisitor) error {
	if r.Text != nil {
		return visitor.VisitText(r.Text)
	}
	if r.JsonObject != nil {
		return visitor.VisitJsonObject(r.JsonObject)
	}
	return fmt.Errorf("type %T does not define a non-empty union type", r)
}

func (r *ResponseFormat) validate() error {
	if r == nil {
		return fmt.Errorf("type %T is nil", r)
	}
	var fields []string
	if r.Text != nil {
		fields = append(fields, "text")
	}
	if r.JsonObject != nil {
		fields = append(fields, "json_object")
	}
	if len(fields) == 0 {
		if r.Type != "" {
			return fmt.Errorf("type %T defines a discriminant set to %q but the field is not set", r, r.Type)
		}
		return fmt.Errorf("type %T is empty", r)
	}
	if len(fields) > 1 {
		return fmt.Errorf("type %T defines values for %s, but only one value is allowed", r, fields)
	}
	if r.Type != "" {
		field := fields[0]
		if r.Type != field {
			return fmt.Errorf(
				"type %T defines a discriminant set to %q, but it does not match the %T field; either remove or update the discriminant to match",
				r,
				r.Type,
				r,
			)
		}
	}
	return nil
}

type SingleGeneration struct {
	Id   string `json:"id" url:"id"`
	Text string `json:"text" url:"text"`
	// Refers to the nth generation. Only present when `num_generations` is greater than zero.
	Index      *int     `json:"index,omitempty" url:"index,omitempty"`
	Likelihood *float64 `json:"likelihood,omitempty" url:"likelihood,omitempty"`
	// Only returned if `return_likelihoods` is set to `GENERATION` or `ALL`. The likelihood refers to the average log-likelihood of the entire specified string, which is useful for [evaluating the performance of your model](likelihood-eval), especially if you've created a [custom model](https://docs.cohere.com/docs/training-custom-models). Individual token likelihoods provide the log-likelihood of each token. The first token will not have a likelihood.
	TokenLikelihoods []*SingleGenerationTokenLikelihoodsItem `json:"token_likelihoods,omitempty" url:"token_likelihoods,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (s *SingleGeneration) GetId() string {
	if s == nil {
		return ""
	}
	return s.Id
}

func (s *SingleGeneration) GetText() string {
	if s == nil {
		return ""
	}
	return s.Text
}

func (s *SingleGeneration) GetIndex() *int {
	if s == nil {
		return nil
	}
	return s.Index
}

func (s *SingleGeneration) GetLikelihood() *float64 {
	if s == nil {
		return nil
	}
	return s.Likelihood
}

func (s *SingleGeneration) GetTokenLikelihoods() []*SingleGenerationTokenLikelihoodsItem {
	if s == nil {
		return nil
	}
	return s.TokenLikelihoods
}

func (s *SingleGeneration) GetExtraProperties() map[string]interface{} {
	return s.extraProperties
}

func (s *SingleGeneration) UnmarshalJSON(data []byte) error {
	type unmarshaler SingleGeneration
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*s = SingleGeneration(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *s)
	if err != nil {
		return err
	}
	s.extraProperties = extraProperties
	s.rawJSON = json.RawMessage(data)
	return nil
}

func (s *SingleGeneration) String() string {
	if len(s.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(s.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(s); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", s)
}

type SingleGenerationInStream struct {
	Id string `json:"id" url:"id"`
	// Full text of the generation.
	Text string `json:"text" url:"text"`
	// Refers to the nth generation. Only present when `num_generations` is greater than zero.
	Index        *int         `json:"index,omitempty" url:"index,omitempty"`
	FinishReason FinishReason `json:"finish_reason" url:"finish_reason"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (s *SingleGenerationInStream) GetId() string {
	if s == nil {
		return ""
	}
	return s.Id
}

func (s *SingleGenerationInStream) GetText() string {
	if s == nil {
		return ""
	}
	return s.Text
}

func (s *SingleGenerationInStream) GetIndex() *int {
	if s == nil {
		return nil
	}
	return s.Index
}

func (s *SingleGenerationInStream) GetFinishReason() FinishReason {
	if s == nil {
		return ""
	}
	return s.FinishReason
}

func (s *SingleGenerationInStream) GetExtraProperties() map[string]interface{} {
	return s.extraProperties
}

func (s *SingleGenerationInStream) UnmarshalJSON(data []byte) error {
	type unmarshaler SingleGenerationInStream
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*s = SingleGenerationInStream(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *s)
	if err != nil {
		return err
	}
	s.extraProperties = extraProperties
	s.rawJSON = json.RawMessage(data)
	return nil
}

func (s *SingleGenerationInStream) String() string {
	if len(s.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(s.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(s); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", s)
}

type SingleGenerationTokenLikelihoodsItem struct {
	Token      string  `json:"token" url:"token"`
	Likelihood float64 `json:"likelihood" url:"likelihood"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (s *SingleGenerationTokenLikelihoodsItem) GetToken() string {
	if s == nil {
		return ""
	}
	return s.Token
}

func (s *SingleGenerationTokenLikelihoodsItem) GetLikelihood() float64 {
	if s == nil {
		return 0
	}
	return s.Likelihood
}

func (s *SingleGenerationTokenLikelihoodsItem) GetExtraProperties() map[string]interface{} {
	return s.extraProperties
}

func (s *SingleGenerationTokenLikelihoodsItem) UnmarshalJSON(data []byte) error {
	type unmarshaler SingleGenerationTokenLikelihoodsItem
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*s = SingleGenerationTokenLikelihoodsItem(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *s)
	if err != nil {
		return err
	}
	s.extraProperties = extraProperties
	s.rawJSON = json.RawMessage(data)
	return nil
}

func (s *SingleGenerationTokenLikelihoodsItem) String() string {
	if len(s.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(s.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(s); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", s)
}

// StreamedChatResponse is returned in streaming mode (specified with `stream=True` in the request).
type StreamedChatResponse struct {
	EventType               string
	StreamStart             *ChatStreamStartEvent
	SearchQueriesGeneration *ChatSearchQueriesGenerationEvent
	SearchResults           *ChatSearchResultsEvent
	TextGeneration          *ChatTextGenerationEvent
	CitationGeneration      *ChatCitationGenerationEvent
	ToolCallsGeneration     *ChatToolCallsGenerationEvent
	StreamEnd               *ChatStreamEndEvent
	ToolCallsChunk          *ChatToolCallsChunkEvent
	Debug                   *ChatDebugEvent
}

func (s *StreamedChatResponse) GetEventType() string {
	if s == nil {
		return ""
	}
	return s.EventType
}

func (s *StreamedChatResponse) GetStreamStart() *ChatStreamStartEvent {
	if s == nil {
		return nil
	}
	return s.StreamStart
}

func (s *StreamedChatResponse) GetSearchQueriesGeneration() *ChatSearchQueriesGenerationEvent {
	if s == nil {
		return nil
	}
	return s.SearchQueriesGeneration
}

func (s *StreamedChatResponse) GetSearchResults() *ChatSearchResultsEvent {
	if s == nil {
		return nil
	}
	return s.SearchResults
}

func (s *StreamedChatResponse) GetTextGeneration() *ChatTextGenerationEvent {
	if s == nil {
		return nil
	}
	return s.TextGeneration
}

func (s *StreamedChatResponse) GetCitationGeneration() *ChatCitationGenerationEvent {
	if s == nil {
		return nil
	}
	return s.CitationGeneration
}

func (s *StreamedChatResponse) GetToolCallsGeneration() *ChatToolCallsGenerationEvent {
	if s == nil {
		return nil
	}
	return s.ToolCallsGeneration
}

func (s *StreamedChatResponse) GetStreamEnd() *ChatStreamEndEvent {
	if s == nil {
		return nil
	}
	return s.StreamEnd
}

func (s *StreamedChatResponse) GetToolCallsChunk() *ChatToolCallsChunkEvent {
	if s == nil {
		return nil
	}
	return s.ToolCallsChunk
}

func (s *StreamedChatResponse) GetDebug() *ChatDebugEvent {
	if s == nil {
		return nil
	}
	return s.Debug
}

func (s *StreamedChatResponse) UnmarshalJSON(data []byte) error {
	var unmarshaler struct {
		EventType string `json:"event_type"`
	}
	if err := json.Unmarshal(data, &unmarshaler); err != nil {
		return err
	}
	s.EventType = unmarshaler.EventType
	if unmarshaler.EventType == "" {
		return fmt.Errorf("%T did not include discriminant event_type", s)
	}
	switch unmarshaler.EventType {
	case "stream-start":
		value := new(ChatStreamStartEvent)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		s.StreamStart = value
	case "search-queries-generation":
		value := new(ChatSearchQueriesGenerationEvent)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		s.SearchQueriesGeneration = value
	case "search-results":
		value := new(ChatSearchResultsEvent)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		s.SearchResults = value
	case "text-generation":
		value := new(ChatTextGenerationEvent)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		s.TextGeneration = value
	case "citation-generation":
		value := new(ChatCitationGenerationEvent)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		s.CitationGeneration = value
	case "tool-calls-generation":
		value := new(ChatToolCallsGenerationEvent)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		s.ToolCallsGeneration = value
	case "stream-end":
		value := new(ChatStreamEndEvent)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		s.StreamEnd = value
	case "tool-calls-chunk":
		value := new(ChatToolCallsChunkEvent)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		s.ToolCallsChunk = value
	case "debug":
		value := new(ChatDebugEvent)
		if err := json.Unmarshal(data, &value); err != nil {
			return err
		}
		s.Debug = value
	}
	return nil
}

func (s StreamedChatResponse) MarshalJSON() ([]byte, error) {
	if err := s.validate(); err != nil {
		return nil, err
	}
	if s.StreamStart != nil {
		return internal.MarshalJSONWithExtraProperty(s.StreamStart, "event_type", "stream-start")
	}
	if s.SearchQueriesGeneration != nil {
		return internal.MarshalJSONWithExtraProperty(s.SearchQueriesGeneration, "event_type", "search-queries-generation")
	}
	if s.SearchResults != nil {
		return internal.MarshalJSONWithExtraProperty(s.SearchResults, "event_type", "search-results")
	}
	if s.TextGeneration != nil {
		return internal.MarshalJSONWithExtraProperty(s.TextGeneration, "event_type", "text-generation")
	}
	if s.CitationGeneration != nil {
		return internal.MarshalJSONWithExtraProperty(s.CitationGeneration, "event_type", "citation-generation")
	}
	if s.ToolCallsGeneration != nil {
		return internal.MarshalJSONWithExtraProperty(s.ToolCallsGeneration, "event_type", "tool-calls-generation")
	}
	if s.StreamEnd != nil {
		return internal.MarshalJSONWithExtraProperty(s.StreamEnd, "event_type", "stream-end")
	}
	if s.ToolCallsChunk != nil {
		return internal.MarshalJSONWithExtraProperty(s.ToolCallsChunk, "event_type", "tool-calls-chunk")
	}
	if s.Debug != nil {
		return internal.MarshalJSONWithExtraProperty(s.Debug, "event_type", "debug")
	}
	return nil, fmt.Errorf("type %T does not define a non-empty union type", s)
}

type StreamedChatResponseVisitor interface {
	VisitStreamStart(*ChatStreamStartEvent) error
	VisitSearchQueriesGeneration(*ChatSearchQueriesGenerationEvent) error
	VisitSearchResults(*ChatSearchResultsEvent) error
	VisitTextGeneration(*ChatTextGenerationEvent) error
	VisitCitationGeneration(*ChatCitationGenerationEvent) error
	VisitToolCallsGeneration(*ChatToolCallsGenerationEvent) error
	VisitStreamEnd(*ChatStreamEndEvent) error
	VisitToolCallsChunk(*ChatToolCallsChunkEvent) error
	VisitDebug(*ChatDebugEvent) error
}

func (s *StreamedChatResponse) Accept(visitor StreamedChatResponseVisitor) error {
	if s.StreamStart != nil {
		return visitor.VisitStreamStart(s.StreamStart)
	}
	if s.SearchQueriesGeneration != nil {
		return visitor.VisitSearchQueriesGeneration(s.SearchQueriesGeneration)
	}
	if s.SearchResults != nil {
		return visitor.VisitSearchResults(s.SearchResults)
	}
	if s.TextGeneration != nil {
		return visitor.VisitTextGeneration(s.TextGeneration)
	}
	if s.CitationGeneration != nil {
		return visitor.VisitCitationGeneration(s.CitationGeneration)
	}
	if s.ToolCallsGeneration != nil {
		return visitor.VisitToolCallsGeneration(s.ToolCallsGeneration)
	}
	if s.StreamEnd != nil {
		return visitor.VisitStreamEnd(s.StreamEnd)
	}
	if s.ToolCallsChunk != nil {
		return visitor.VisitToolCallsChunk(s.ToolCallsChunk)
	}
	if s.Debug != nil {
		return visitor.VisitDebug(s.Debug)
	}
	return fmt.Errorf("type %T does not define a non-empty union type", s)
}

func (s *StreamedChatResponse) validate() error {
	if s == nil {
		return fmt.Errorf("type %T is nil", s)
	}
	var fields []string
	if s.StreamStart != nil {
		fields = append(fields, "stream-start")
	}
	if s.SearchQueriesGeneration != nil {
		fields = append(fields, "search-queries-generation")
	}
	if s.SearchResults != nil {
		fields = append(fields, "search-results")
	}
	if s.TextGeneration != nil {
		fields = append(fields, "text-generation")
	}
	if s.CitationGeneration != nil {
		fields = append(fields, "citation-generation")
	}
	if s.ToolCallsGeneration != nil {
		fields = append(fields, "tool-calls-generation")
	}
	if s.StreamEnd != nil {
		fields = append(fields, "stream-end")
	}
	if s.ToolCallsChunk != nil {
		fields = append(fields, "tool-calls-chunk")
	}
	if s.Debug != nil {
		fields = append(fields, "debug")
	}
	if len(fields) == 0 {
		if s.EventType != "" {
			return fmt.Errorf("type %T defines a discriminant set to %q but the field is not set", s, s.EventType)
		}
		return fmt.Errorf("type %T is empty", s)
	}
	if len(fields) > 1 {
		return fmt.Errorf("type %T defines values for %s, but only one value is allowed", s, fields)
	}
	if s.EventType != "" {
		field := fields[0]
		if s.EventType != field {
			return fmt.Errorf(
				"type %T defines a discriminant set to %q, but it does not match the %T field; either remove or update the discriminant to match",
				s,
				s.EventType,
				s,
			)
		}
	}
	return nil
}

// One of `low`, `medium`, `high`, or `auto`, defaults to `auto`. Controls how close to the original text the summary is. `high` extractiveness summaries will lean towards reusing sentences verbatim, while `low` extractiveness summaries will tend to paraphrase more. If `auto` is selected, the best option will be picked based on the input text.
type SummarizeRequestExtractiveness string

const (
	SummarizeRequestExtractivenessLow    SummarizeRequestExtractiveness = "low"
	SummarizeRequestExtractivenessMedium SummarizeRequestExtractiveness = "medium"
	SummarizeRequestExtractivenessHigh   SummarizeRequestExtractiveness = "high"
)

func NewSummarizeRequestExtractivenessFromString(s string) (SummarizeRequestExtractiveness, error) {
	switch s {
	case "low":
		return SummarizeRequestExtractivenessLow, nil
	case "medium":
		return SummarizeRequestExtractivenessMedium, nil
	case "high":
		return SummarizeRequestExtractivenessHigh, nil
	}
	var t SummarizeRequestExtractiveness
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (s SummarizeRequestExtractiveness) Ptr() *SummarizeRequestExtractiveness {
	return &s
}

// One of `paragraph`, `bullets`, or `auto`, defaults to `auto`. Indicates the style in which the summary will be delivered - in a free form paragraph or in bullet points. If `auto` is selected, the best option will be picked based on the input text.
type SummarizeRequestFormat string

const (
	SummarizeRequestFormatParagraph SummarizeRequestFormat = "paragraph"
	SummarizeRequestFormatBullets   SummarizeRequestFormat = "bullets"
)

func NewSummarizeRequestFormatFromString(s string) (SummarizeRequestFormat, error) {
	switch s {
	case "paragraph":
		return SummarizeRequestFormatParagraph, nil
	case "bullets":
		return SummarizeRequestFormatBullets, nil
	}
	var t SummarizeRequestFormat
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (s SummarizeRequestFormat) Ptr() *SummarizeRequestFormat {
	return &s
}

// One of `short`, `medium`, `long`, or `auto` defaults to `auto`. Indicates the approximate length of the summary. If `auto` is selected, the best option will be picked based on the input text.
type SummarizeRequestLength string

const (
	SummarizeRequestLengthShort  SummarizeRequestLength = "short"
	SummarizeRequestLengthMedium SummarizeRequestLength = "medium"
	SummarizeRequestLengthLong   SummarizeRequestLength = "long"
)

func NewSummarizeRequestLengthFromString(s string) (SummarizeRequestLength, error) {
	switch s {
	case "short":
		return SummarizeRequestLengthShort, nil
	case "medium":
		return SummarizeRequestLengthMedium, nil
	case "long":
		return SummarizeRequestLengthLong, nil
	}
	var t SummarizeRequestLength
	return "", fmt.Errorf("%s is not a valid %T", s, t)
}

func (s SummarizeRequestLength) Ptr() *SummarizeRequestLength {
	return &s
}

type SummarizeResponse struct {
	// Generated ID for the summary
	Id *string `json:"id,omitempty" url:"id,omitempty"`
	// Generated summary for the text
	Summary *string  `json:"summary,omitempty" url:"summary,omitempty"`
	Meta    *ApiMeta `json:"meta,omitempty" url:"meta,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (s *SummarizeResponse) GetId() *string {
	if s == nil {
		return nil
	}
	return s.Id
}

func (s *SummarizeResponse) GetSummary() *string {
	if s == nil {
		return nil
	}
	return s.Summary
}

func (s *SummarizeResponse) GetMeta() *ApiMeta {
	if s == nil {
		return nil
	}
	return s.Meta
}

func (s *SummarizeResponse) GetExtraProperties() map[string]interface{} {
	return s.extraProperties
}

func (s *SummarizeResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler SummarizeResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*s = SummarizeResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *s)
	if err != nil {
		return err
	}
	s.extraProperties = extraProperties
	s.rawJSON = json.RawMessage(data)
	return nil
}

func (s *SummarizeResponse) String() string {
	if len(s.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(s.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(s); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", s)
}

type TokenizeResponse struct {
	// An array of tokens, where each token is an integer.
	Tokens       []int    `json:"tokens,omitempty" url:"tokens,omitempty"`
	TokenStrings []string `json:"token_strings" url:"token_strings"`
	Meta         *ApiMeta `json:"meta,omitempty" url:"meta,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (t *TokenizeResponse) GetTokens() []int {
	if t == nil {
		return nil
	}
	return t.Tokens
}

func (t *TokenizeResponse) GetTokenStrings() []string {
	if t == nil {
		return nil
	}
	return t.TokenStrings
}

func (t *TokenizeResponse) GetMeta() *ApiMeta {
	if t == nil {
		return nil
	}
	return t.Meta
}

func (t *TokenizeResponse) GetExtraProperties() map[string]interface{} {
	return t.extraProperties
}

func (t *TokenizeResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler TokenizeResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*t = TokenizeResponse(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *t)
	if err != nil {
		return err
	}
	t.extraProperties = extraProperties
	t.rawJSON = json.RawMessage(data)
	return nil
}

func (t *TokenizeResponse) String() string {
	if len(t.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(t.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(t); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", t)
}

type Tool struct {
	// The name of the tool to be called. Valid names contain only the characters `a-z`, `A-Z`, `0-9`, `_` and must not begin with a digit.
	Name string `json:"name" url:"name"`
	// The description of what the tool does, the model uses the description to choose when and how to call the function.
	Description string `json:"description" url:"description"`
	// The input parameters of the tool. Accepts a dictionary where the key is the name of the parameter and the value is the parameter spec. Valid parameter names contain only the characters `a-z`, `A-Z`, `0-9`, `_` and must not begin with a digit.
	// ```
	//
	//	{
	//	  "my_param": {
	//	    "description": <string>,
	//	    "type": <string>, // any python data type, such as 'str', 'bool'
	//	    "required": <boolean>
	//	  }
	//	}
	//
	// ```
	ParameterDefinitions map[string]*ToolParameterDefinitionsValue `json:"parameter_definitions,omitempty" url:"parameter_definitions,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (t *Tool) GetName() string {
	if t == nil {
		return ""
	}
	return t.Name
}

func (t *Tool) GetDescription() string {
	if t == nil {
		return ""
	}
	return t.Description
}

func (t *Tool) GetParameterDefinitions() map[string]*ToolParameterDefinitionsValue {
	if t == nil {
		return nil
	}
	return t.ParameterDefinitions
}

func (t *Tool) GetExtraProperties() map[string]interface{} {
	return t.extraProperties
}

func (t *Tool) UnmarshalJSON(data []byte) error {
	type unmarshaler Tool
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*t = Tool(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *t)
	if err != nil {
		return err
	}
	t.extraProperties = extraProperties
	t.rawJSON = json.RawMessage(data)
	return nil
}

func (t *Tool) String() string {
	if len(t.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(t.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(t); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", t)
}

// Contains the tool calls generated by the model. Use it to invoke your tools.
type ToolCall struct {
	// Name of the tool to call.
	Name string `json:"name" url:"name"`
	// The name and value of the parameters to use when invoking a tool.
	Parameters map[string]interface{} `json:"parameters" url:"parameters"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (t *ToolCall) GetName() string {
	if t == nil {
		return ""
	}
	return t.Name
}

func (t *ToolCall) GetParameters() map[string]interface{} {
	if t == nil {
		return nil
	}
	return t.Parameters
}

func (t *ToolCall) GetExtraProperties() map[string]interface{} {
	return t.extraProperties
}

func (t *ToolCall) UnmarshalJSON(data []byte) error {
	type unmarshaler ToolCall
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*t = ToolCall(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *t)
	if err != nil {
		return err
	}
	t.extraProperties = extraProperties
	t.rawJSON = json.RawMessage(data)
	return nil
}

func (t *ToolCall) String() string {
	if len(t.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(t.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(t); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", t)
}

// Contains the chunk of the tool call generation in the stream.
type ToolCallDelta struct {
	// Name of the tool call
	Name *string `json:"name,omitempty" url:"name,omitempty"`
	// Index of the tool call generated
	Index *float64 `json:"index,omitempty" url:"index,omitempty"`
	// Chunk of the tool parameters
	Parameters *string `json:"parameters,omitempty" url:"parameters,omitempty"`
	// Chunk of the tool plan text
	Text *string `json:"text,omitempty" url:"text,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (t *ToolCallDelta) GetName() *string {
	if t == nil {
		return nil
	}
	return t.Name
}

func (t *ToolCallDelta) GetIndex() *float64 {
	if t == nil {
		return nil
	}
	return t.Index
}

func (t *ToolCallDelta) GetParameters() *string {
	if t == nil {
		return nil
	}
	return t.Parameters
}

func (t *ToolCallDelta) GetText() *string {
	if t == nil {
		return nil
	}
	return t.Text
}

func (t *ToolCallDelta) GetExtraProperties() map[string]interface{} {
	return t.extraProperties
}

func (t *ToolCallDelta) UnmarshalJSON(data []byte) error {
	type unmarshaler ToolCallDelta
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*t = ToolCallDelta(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *t)
	if err != nil {
		return err
	}
	t.extraProperties = extraProperties
	t.rawJSON = json.RawMessage(data)
	return nil
}

func (t *ToolCallDelta) String() string {
	if len(t.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(t.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(t); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", t)
}

type ToolParameterDefinitionsValue struct {
	// The description of the parameter.
	Description *string `json:"description,omitempty" url:"description,omitempty"`
	// The type of the parameter. Must be a valid Python type.
	Type string `json:"type" url:"type"`
	// Denotes whether the parameter is always present (required) or not. Defaults to not required.
	Required *bool `json:"required,omitempty" url:"required,omitempty"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (t *ToolParameterDefinitionsValue) GetDescription() *string {
	if t == nil {
		return nil
	}
	return t.Description
}

func (t *ToolParameterDefinitionsValue) GetType() string {
	if t == nil {
		return ""
	}
	return t.Type
}

func (t *ToolParameterDefinitionsValue) GetRequired() *bool {
	if t == nil {
		return nil
	}
	return t.Required
}

func (t *ToolParameterDefinitionsValue) GetExtraProperties() map[string]interface{} {
	return t.extraProperties
}

func (t *ToolParameterDefinitionsValue) UnmarshalJSON(data []byte) error {
	type unmarshaler ToolParameterDefinitionsValue
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*t = ToolParameterDefinitionsValue(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *t)
	if err != nil {
		return err
	}
	t.extraProperties = extraProperties
	t.rawJSON = json.RawMessage(data)
	return nil
}

func (t *ToolParameterDefinitionsValue) String() string {
	if len(t.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(t.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(t); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", t)
}

type ToolResult struct {
	Call    *ToolCall                `json:"call" url:"call"`
	Outputs []map[string]interface{} `json:"outputs" url:"outputs"`

	extraProperties map[string]interface{}
	rawJSON         json.RawMessage
}

func (t *ToolResult) GetCall() *ToolCall {
	if t == nil {
		return nil
	}
	return t.Call
}

func (t *ToolResult) GetOutputs() []map[string]interface{} {
	if t == nil {
		return nil
	}
	return t.Outputs
}

func (t *ToolResult) GetExtraProperties() map[string]interface{} {
	return t.extraProperties
}

func (t *ToolResult) UnmarshalJSON(data []byte) error {
	type unmarshaler ToolResult
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*t = ToolResult(value)
	extraProperties, err := internal.ExtractExtraProperties(data, *t)
	if err != nil {
		return err
	}
	t.extraProperties = extraProperties
	t.rawJSON = json.RawMessage(data)
	return nil
}

func (t *ToolResult) String() string {
	if len(t.rawJSON) > 0 {
		if value, err := internal.StringifyJSON(t.rawJSON); err == nil {
			return value
		}
	}
	if value, err := internal.StringifyJSON(t); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", t)
}
